هوش مصنوعی برای نظارت تصویری از برنامه‌های نرم‌افزاری رایانه ای استفاده می‌کند که به منظور شناسایی انسان، وسایل نقلیه، اشیاء و رویدادها، صدا و تصاویر دوربین‌های نظارت تصویری را تجزیه و تحلیل می‌کند. برنامه پیمانکاران امنیتی نرم‌افزاری است برای تعریف مناطق محدود شده در دید دوربین (مانند محوطه حصارکشی شده، پارکینگ اما نه پیاده‌رو یا خیابان عمومی خارج از محدوده) برای ساعاتی از روز (مانند بعد از تعطیل کردن مشاغل) برای اموالی که توسط نظارت دوربین محافظت می‌شود. هوش مصنوعی (AI) در صورت مشاهده متجاوز به «قانون» مبنی بر مجاز نبودن هیچ شخصی در آن منطقه در روز، هشدار می‌فرستد.
برنامه هوش مصنوعی با استفاده از بینایی ماشین کار می‌کند. بینایی ماشین مجموعه ای از الگوریتم‌ها یا رویه‌های ریاضی است که مانند یک فلوچارت یا مجموعه ای از سؤال‌ها برای مقایسه جسم دیده شده با صدها هزار تصویر مرجع ذخیره شده از انسان در حالت‌ها، زاویه‌ها، موقعیت‌ها و حرکت‌های مختلف کار می‌کند. هوش مصنوعی از خود می‌پرسد که آیا جسم مشاهده شده مانند تصاویر مرجع حرکت می‌کند، آیا ارتفاع آن تقریباً نسبت به عرض آن یکسان است، آیا دارای دو بازو و دو پای مشخص است، آیا با سرعت مشابه حرکت می‌کند و آیا به جای افقی عمودی است. بسیاری از سؤالات دیگر مانند درجه انعکاس جسم، درجه ثبات یا لرزشی آن و همواری حرکت آن، محتمل است. با ترکیب همه مقادیر سؤالات مختلف، یک رتبه‌بندی کلی بدست می‌آید که این احتمال را به هوش مصنوعی می‌دهد که این شیء انسان است یا نیست. اگر مقدار بیش از حد تعیین شده باشد، هشدار ارسال می‌شود. مشخصه این برنامه‌ها این است که آنها تا حدی خودآموز هستند و یادمی‌گیرند. به عنوان مثال انسان یا وسایل نقلیه در بخش‌های خاصی از تصویر تحت نظارت - آن مناطق نزدیک به دوربین - تا سایر قسمت‌ها بزرگتر به نظر می‌رسند.
علاوه بر قانون ساده محدود کردن انسان یا وسایل نقلیه از مناطق خاص در ساعات مشخصی از روز، می‌توان قوانین پیچیده تری نیز وضع کرد. کاربر سیستم ممکن است بخواهد بداند که آیا وسایل نقلیه در یک جهت حرکت می‌کنند یا نه. ممکن است کاربران بخواهند بدانند که بیش از تعداد مشخصی از افراد در یک منطقه خاص وجود دارد. هوش مصنوعی قادر به نظارت همزمان بر صدها دوربین است. توانایی آن در ردیابی متجاوز در فاصله دور یا در زیر باران یا تابش خیره کننده از توانایی انسان در انجام این کار برتر است.
این نوع هوش مصنوعی برای امنیت به عنوان " مبتنی بر قانون " شناخته می‌شود زیرا یک برنامه‌نویس باید برای همه مواردی که کاربر می‌خواهد به آنها هشدار داده شود قوانینی تعیین کند. این رایج‌ترین شکل AI برای امنیت است. امروزه بسیاری از سیستم‌های دوربین نظارت تصویری شامل این نوع توانایی هوش مصنوعی هستند. هارد دیسک که برنامه را در خود جای داده‌است می‌تواند در خود دوربین‌ها قرار داشته باشد یا در یک دستگاه جداگانه باشد که ورودی را از دوربین‌ها دریافت می‌کند.
یک شکل جدید و غیر مبتنی بر قانون از هوش مصنوعی برای امنیت به نام " تجزیه و تحلیل رفتاری " ایجاد شده‌است. این نرم‌افزار کاملاً خودآموز است و هیچ ورودی برنامه‌نویسی اولیه توسط کاربر یا پیمانکار امنیتی ندارد. در این نوع تجزیه و تحلیل، هوش مصنوعی بر اساس مشاهدات خود از الگوهای مختلف مانند اندازه، سرعت، بازتاب، رنگ، گروه‌بندی، جهت عمودی یا افقی و غیره می‌آموزد که رفتار طبیعی برای افراد، وسایل نقلیه، ماشین آلات و محیط چیست. هوش مصنوعی داده‌های بصری را نرمال سازی می‌کند، به این معنی که اشیاء و الگوهای مشاهده شده آن‌ها را طبقه‌بندی و برچسب گذاری می‌کند و به‌طور مداوم تعاریف تصحیح شده‌ای از رفتار طبیعی یا متوسط برای اشیاء مشاهده شده مختلف ایجاد می‌کند. پس از چندین هفته یادگیری با این روش می‌تواند تشخیص دهد که چه مواردی الگو را می‌شکنند. وقتی چنین ناهنجاری‌هایی را مشاهده می‌کند، هشدار می‌فرستد. به عنوان مثال، رانندگی اتومبیل در خیابان امری طبیعی است. اتومبیلی که در حال عبور از پیاده‌رو است، ناهنجاری است. اگر حیاط حصارکشی معمولاً شب خالی باشد، شخصی که وارد آن منطقه می‌شود ناهنجاری است.
محدودیت در توانایی بشر برای نظارت دقیق بر تصاویر زنده از طریق نظارت تصویری، منجر به تقاضای هوش مصنوعی شده‌است که می‌تواند در انجام وظیفه، بهتر عمل کند. انسان‌هایی که بیش از بیست دقیقه در حال تماشای یک مانیتور ویدیویی هستند، ۹۵٪ توانایی خود را در حفظ توجه کافی برای تشخیص وقایع مهم از دست می‌دهند. با دو مانیتور، این دوباره به نصف کاهش می‌یابد. با توجه به اینکه بسیاری از تجهیزات ده‌ها یا حتی صدها دوربین دارند، وظیفه به وضوح فراتر از توانایی انسان است. به‌طور کلی، نمای دوربین از راهروهای خالی، تجهیزات ذخیره‌سازی، پارکینگ‌ها یا ساختمان‌ها بسیار کسل کننده است و بنابراین دقت و توجه، به سرعت کاهش می‌یابد. هنگامی که چندین دوربین کنترل می‌شود، معمولاً با استفاده از یک مانیتور دیواری یا بانک مانیتورهایی که دارای صفحه نمایش تقسیم شده هستند و هر چند ثانیه یکبار بین یک مجموعه دوربین می‌چرخند، خستگی چشم به سرعت طاقت فرسا می‌شود. در حالی که دوربین‌های نظارت تصویری با استقبال چشمگیر کاربران از نمایندگی‌های فروش اتومبیل و مراکز خرید گرفته تا مدارس و مشاغل تا تأسیسات بسیار ایمن مانند نیروگاه‌های هسته ای گسترش یافته‌است، با وجود عقاید تشخیص داده شد که نظارت تصویری توسط افسران انسانی (که «اپراتورها» نیز نامیده می‌شود) غیر عملی است و بی اثر است. سیستم‌های گسترده نظارت تصویری پس از وقوع سرقت، آتش‌سوزی، حمله یا حادثه، صرفاً برای استفاده احتمالی قانونی (دادگاهی) برای شناسایی شخصی منتقل شدند. در جاهایی که از نماهای دوربین عریض استفاده شده‌است، مخصوصاً برای مکان‌های بزرگ در فضای باز، محدودیت‌های شدیدی حتی برای این منظور به دلیل وضوح ناکافی کشف شده‌است. در این موارد شناسایی متجاوز یا مرتکب جرم غیرممکن است زیرا تصویر آنها روی مانیتور خیلی کوچک است. فقط می‌توانیم انسان‌ها را جداگانه از حیوانات و وسایل نقلیه تشخیص دهیم.
در پاسخ به کمبودهای نگهبانان انسانی برای تماشای طولانی مدت مانیتورهای نظارتی، اولین راه حل افزودن ردیاب‌های حرکتی به دوربین‌ها بود. دلیل این امر این بود که با اقدام یک متجاوز یا عامل جنایت، هشدار به مأمور نظارت از راه دور ارسال می‌شود و از نیاز به هوشیاری مداوم انسانی جلوگیری می‌کند. مشکل این بود که در یک محیط بیرونی حرکت مداوم یا تغییر پیکسل‌هایی وجود دارد که کل تصویر مشاهده شده روی صفحه را تشکیل می‌دهد. حرکت برگ‌ها روی درختانی که در باد می‌وزند، اشیاء روی زمین، حشرات، پرندگان، سگ‌ها، سایه‌ها، چراغ‌ها، پرتوهای خورشید و غیره همه حرکت را تشکیل می‌دهند. این باعث ایجاد صدها یا حتی هزاران هشدار اشتباه در روز می‌شود و این راه حل را غیر از محیط‌های داخلی در طول ساعات غیرعملیاتی ناکارآمد می‌کند.
تکامل بعدی هشدارهای کاذب را تا حدی کاهش داد اما با هزینه کالیبراسیون دستی پیچیده و زمان بر. در اینجا، تغییرات یک هدف مانند یک فرد یا وسیله نقلیه نسبت به پس زمینه ثابت شناسایی می‌شود. در مواردی که پس زمینه به صورت فصلی یا به دلیل تغییرات دیگر تغییر می‌کند، با گذشت زمان قابلیت اطمینان رو به زوال می‌رود. اقتصادی بودن پاسخ به هشدارهای نادرست بیش از حد، دوباره مانعی را نشان داد و این راه حل کافی نبود.
یادگیری ماشینی تشخیص بصری به الگوها و طبقه‌بندی آن‌ها مربوط می‌شود. تجزیه و تحلیل ویدیوی درست می‌تواند شکل انسان، وسایل نقلیه و قایق‌ها یا اشیاء انتخاب شده را از حرکت کلی همه اشیاء دیگر و ایستای بصری یا تغییرات پیکسل در مانیتور متمایز کند. این کار را با شناخت الگوها انجام می‌دهد. هنگامی که شیء مورد نظر، به عنوان مثال یک انسان، یک قانون از پیش تعیین شده را نقض می‌کند، به عنوان مثال در طی یک بازه زمانی مشخص تعداد افراد در یک منطقه از پیش تعیین شده نباید بیش از صفر باشد، سپس یک هشدار ارسال می‌شود. یک مستطیل قرمز یا اصطلاحاً «جعبه محدود» معمولاً به‌طور خودکار متجاوز شناسایی شده را دنبال می‌کند، و یک کلیپ ویدیویی کوتاه از آن به عنوان هشدار ارسال می‌شود.
شناسایی متجاوزان با استفاده از نظارت تصویری، محدودیت‌های اقتصادی و ماهیت دوربین‌های فیلمبرداری دارد. به‌طور معمول، دوربین‌ها در فضای باز بر روی یک زاویه دید عریض تنظیم می‌شوند و با این وجود از مسافت زیادی به بیرون نگاه می‌کنند. نرخ فریم در ثانیه و دامنه پویا برای رسیدگی به مناطق با نور زیاد و مناطق کم نور، دوربین را بیشتر به چالش می‌کشد تا در واقع برای دیدن یک متجاوز انسانی در حال حرکت مناسب باشد. در شب، حتی در مکان‌های بیرونی روشن، سوژه در حال حرکت در هر فریم در هر ثانیه نور کافی را به خود نمی‌گیرد - مگر اینکه کاملاً نزدیک دوربین باشد - و به عنوان یک حلقه نازک یا شبح یا کاملاً نامرئی ظاهر می‌شود. شرایط تابش خیره کننده، تیرگی نسبی، باران، برف، مه و تاریکی همه این مسئله را پیچیده می‌کنند. حتی وقتی انسان در این شرایط مستقیماً به مکان واقعی روی مانیتور یک سوژه نگاه کند، سوژه معمولاً تشخیص داده نمی‌شود. هوش مصنوعی قادر است بی طرفانه به‌طور همزمان به کل تصویر و تصاویر دوربین‌ها نگاه کند. با استفاده از مدل‌های آماریِ درجات انحراف از الگوی آموخته شده خود در مورد آنچه که شکل انسانی را تشکیل می‌دهد، یک متجاوز با قابلیت اطمینان بالا و میزان هشدار کاذب کم حتی در شرایط نامساعد، شناسایی خواهد کرد. یادگیری آن تقریباً بر اساس یک چهارم میلیون تصویر از انسان‌ها در موقعیت‌های مختلف، زاویه‌ها، وضعیت‌ها و غیره شکل گرفته‌است.
یک دوربین یک مگاپیکسلی با تجزیه و تحلیل ویدیویی پردازنده قادر بود انسان را در فاصله حدود ۳۵۰ فوت (معادل ۱۰۷ متر) و زاویه دید حدود ۳۰ درجه در شرایط غیر ایدئال تشخیص دهد. قوانینی را می‌توان برای «حصار مجازی» یا نفوذ به یک منطقه از پیش تعریف شده تنظیم کرد. می‌توان قوانینی را برای حرکت جهت دار، اشیاء به جا مانده، تشکیل جمعیت و برخی شرایط دیگر تعیین کرد. هوش مصنوعی برای نظارت تصویری به‌طور گسترده‌ای در چین استفاده می‌شود. نظارت گسترده در چین را ببینید.
یکی از قدرتمندترین ویژگی‌های سیستم این است که یک افسر انسانی یا اپراتور، با دریافت هشدار از هوش مصنوعی، می‌تواند بلافاصله از طریق بلندگوهای آدرس عمومی در فضای باز با متجاوز صحبت کند. این از ارزش بازدارندگی بالایی برخوردار بود زیرا بیشتر جنایات فرصت طلبانه هستند و هنگامی که فرد زنده با آن‌ها صحبت می‌کند ریسک نفوذ برای متجاوز به حدی زیاد می‌شود که به احتمال زیاد از نفوذ دست کشیده و عقب‌نشینی می‌کنند. افسر امنیتی اقدامات متجاوز را توصیف می‌کند به طوری که متجاوز شک نخواهد داشت که یک فرد واقعی آن‌ها را تماشا می‌کند. افسر اعلام می‌کند که متجاوز قانون را نقض می‌کند و با نیروی انتظامی تماس گرفته می‌شود و آن‌ها در حال ضبط فیلم هستند.
پلیس تعداد عظیمی از هشدارهای کاذب را از طریق دزدگیرها دریافت می‌کند. در حقیقت صنعت امنیت گزارش می‌دهد که بیش از ۹۸٪ این هشدارها اشتباه است. بر این اساس، پلیس با هشدارهای دزدگیر پاسخ بسیار کمتری می‌دهد و پاسخ به سایت می‌تواند از بیست دقیقه تا دو ساعت طول بکشد. در مقابل، جرم کشف شده تحلیلی ویدئویی به افسر نظارت مرکزی گزارش می‌شود، که با چشم خود تأیید می‌کند که این یک جرم واقعی در حال انجام است. وی سپس به پلیس مخابره می‌کند که بیشترین اولویت را به چنین تماس‌هایی می‌دهند.
در حالی که تجزیه و تحلیل ویدئویی مبتنی بر قانون برای بسیاری از برنامه‌های امنیتی، اقتصادی و قابل اعتماد، کار می‌کند، شرایط بسیاری وجود دارد که نمی‌تواند کار کند. برای یک منطقه داخلی یا خارجی که هیچ‌کس در ساعات خاصی از شبانه روز نباید در آن حضور داشته باشد، به عنوان مثال در طول شب، یا برای مناطقی که هیچ‌کس در هر زمانی نباید آن جا باشد مانند برج سلول، تجزیه و تحلیل سنتی مبتنی بر قانون کاملاً مناسب است. در مثال برج سلول، زمان نادری که ممکن است یک تکنسین خدمات برای دسترسی به منطقه مورد نیاز باشد، به سادگی نیاز به کد عبور دارد تا پاسخ نظارت را «در آزمایش» قرار دهد یا برای مدت کوتاهی که شخص مجاز در آنجا است، غیرفعال شود.
اما بسیاری از نیازهای امنیتی در محیط‌های فعال وجود دارد که صدها یا هزاران نفر به‌طور مداوم در آن مکان‌ها حضور دارند. به عنوان مثال، محوطه دانشگاه، یک کارخانه فعال، یک بیمارستان یا هر مرکز عملیاتی فعال. نمی‌توان قوانینی را تعیین کرد که بین افراد قانونی و مجرمان یا افراد ناشایست تبعیض قائل شود.
(با استفاده از تجزیه و تحلیل رفتاری، یک هوش مصنوعی مبتنی بر خودآموزی، نامبتنی بر قانون، داده‌ها را از دوربین‌های ویدئویی می‌گیرد و به‌طور مداوم اشیاء و رویدادهایی را که می‌بیند طبقه‌بندی می‌کند. به عنوان مثال، عبور شخص از یک خیابان یک طبقه‌بندی است. گروهی از مردم طبقه‌بندی دیگر است. وسیله نقلیه یک طبقه‌بندی است، اما با یادگیری مداوم یک اتوبوس عمومی از یک کامیون کوچک و از یک موتورسیکلت تفکیک می‌یابد. با افزایش پیچیدگی، سیستم، الگوهای رفتار انسان را تشخیص می‌دهد. به عنوان مثال، ممکن است مشاهده شود که افراد از یک در (ب) دسترسی کنترل شده به‌طور همزمان عبور می‌کنند. در باز می‌شود، فرد کارت مجوز یا برچسب خود را ارائه می‌دهد، فرد از آنجا عبور می‌کند و در بسته می‌شود. این الگوی فعالیت که به‌طور مکرر مشاهده می‌شود، مبنایی برای آنچه در دید دوربین مشاهده آن صحنه عادی است، می‌شود. حال اگر شخص مجاز در را باز کند اما شخص غیرمجاز دوم، قبل از بسته شدن در از آن عبور کند، این نوعی ناهنجاری است که هشدار ایجاد می‌کند. این نوع تحلیل بسیار پیچیده‌تر از تجزیه و تحلیل مبتنی بر قانون است. در حالی که تجزیه و تحلیل مبتنی بر قانون عمدتاً برای شناسایی متجاوزان به مناطقی است که در اوقات مشخصی از روز معمولاً هیچ‌کس در آن حضور ندارد، تجزیه و تحلیل رفتاری در جایی انجام می‌شود که افراد برای شناسایی چیزهای غیرعادی فعال هستند.
آتش‌سوزی در فضای باز، همچنین ابر دود در حال افزایش یک اتفاق غیرمعمول است و باعث ایجاد هشدار می‌شود. وسایل نقلیه ای که از مسیر اشتباهی به یک مسیر عبور یک طرفه می‌روند، نوع رویدادی را که دارای یک امضای بصری قوی است، مشخص می‌کند و از الگوی مکرر مشاهده شده از وسایل نقلیه ای که یک مسیر یک طرفه را به‌طور صحیح می‌روند، منحرف می‌شود. کسی که توسط یک مهاجم به زمین پرتاب شود یک اتفاق غیر معمول است که احتمالاً باعث هشدار می‌شود. این وضعیت خاص است؛ بنابراین اگر دوربین، یک سالن ورزشی را که در آن کشتی انجام می‌شود مشاهده می‌کند، هوش مصنوعی می‌آموزد که معمولاً یک انسان دیگری را به زمین می‌اندازد، در این صورت از این مشاهده هشدار نمی‌دهد.
هوش مصنوعی نمی‌داند یا نمی‌فهمد انسان، آتش‌سوزی یا وسیله نقلیه چیست. این به سادگی یافتن خصوصیات این موارد بر اساس اندازه، شکل، رنگ، بازتابندگی، زاویه، جهت‌گیری، حرکت و غیره است. سپس دریافت که اشیاء طبقه‌بندی شده دارای الگوی رفتاری معمولی است. به عنوان مثال، انسان‌ها در پیاده‌روها و گاهی در خیابان‌ها قدم می‌زنند اما زیاد از کناره‌های ساختمان بالا نمی‌روند. وسایل نقلیه در خیابان‌ها حرکت می‌کنند اما در پیاده‌روها حرکت نمی‌کنند؛ بنابراین رفتار ناهنجار کسی که از ساختمان بالا می‌رود یا وسیله نقلیه ای که به سمت پیاده‌رو منحرف می‌شود، باعث هشدار می‌شود.
سیستم‌های هشدار معمولی به گونه ای طراحی شده‌اند که موارد مثبت واقعی (وقایع واقعی جرم) را از دست ندهند و تا حد ممکن کمترین میزان هشدار کاذب را دارند. در این راستا، دزدگیرها موارد مثبت واقعی اندکی را از دست می‌دهند اما حتی در محیط داخلی کنترل شده نیز میزان هشدار کاذب بسیار بالایی دارند. دوربین‌های تشخیص حرکت برخی از موارد مثبت واقعی را از دست می‌دهند اما در یک محیط بیرونی با هشدارهای غلط غافلگیرکننده مواجه هستند. تجزیه و تحلیل مبتنی بر قانون به‌طور قابل اعتماد اکثر موارد مثبت واقعی را تشخیص می‌دهد و دارای نرخ پایین مثبت کاذب است، اما نمی‌تواند در محیط‌های فعال اجرا شود و فقط در محیط‌های خالی انجام می‌شود. همچنین آن‌ها به تبعیض ساده در مورد حضور یا عدم حضور متجاوز محدود می‌شوند.
چیزی همانند درگیری یا شکستن رویه امنیتی توسط یک کارمند، پیچیده و نامحدود است که برای تجزیه و تحلیل مبتنی بر قانون امکان تشخیص یا تبعیض وجود ندارد. با تجزیه و تحلیل رفتاری، این امر امکان‌پذیر است. مکان‌هایی که افراد در آن جابجا می‌شوند و کار می‌کنند مشکلی ایجاد نمی‌کنند. با این حال، هوش مصنوعی ممکن است بسیاری از موارد را که غیرعادی به نظر می‌رسند اما ماهیت آنها عادی است، تشخیص دهد. به عنوان مثال، اگر دانشجویان در محوطه در یک میدان پیاده‌روی کنند، این امر به صورت عادی آموخته می‌شود. اگر چند دانشجو تصمیم بگیرند که یک ملحفه بزرگ را به بیرون برده و در معرض باد قرار دهند، ممکن است باعث هشدار شود. به افسر نظارت هشدار داده می‌شود تا به مانیتور خود نگاه کند و ببیند که این رویداد تهدیدی نیست و سپس آن را نادیده می‌گیرد. درجه انحراف از هنجار را که باعث هشدار می‌شود می‌توان طوری تنظیم کرد که فقط غیرعادی‌ترین موارد گزارش شود. با این حال، این هنوز هم روش جدیدی از تعامل انسان و هوش مصنوعی را تشکیل می‌دهد که با ذهنیت سنتی صنعت هشدار مشخص نمی‌شود. این به این دلیل است که هشدارهای کاذب زیادی وجود دارد که ممکن است ارسال آن‌ها برای یک افسر انسانی که می‌تواند به سرعت بررسی کند و تشخیص دهد آیا صحنه نیاز به پاسخ دارد یا نه، ارزشمند باشد. از این نظر، این یک «ضربه به شانه» از هوش مصنوعی است تا انسان به چیزی نگاه کند.
از آنجا که بسیاری از موارد پیچیده به‌طور مداوم در حال پردازش هستند، این نرم‌افزار با رزولوشن بسیار پایین و تنها ۱ CIF نمونه برداری می‌کند تا تقاضای محاسباتی را حفظ کند. وضوح ۱ CIF بدین معنی است که اگر دوربینی که استفاده می‌کند زاویه بازداشته باشد و انسان بسته به شرایط بیش از شصت تا هشتاد فوت فاصله داشته باشد، شیئی به اندازه انسان تشخیص داده نمی‌شود. اجسام بزرگتر مانند وسایل نقلیه یا دود در فواصل بیشتر قابل تشخیص هستند.
سودمندی هوش مصنوعی برای امنیت در خلأ وجود ندارد و توسعه آن نیز صرفاً با مطالعه آکادمیک یا علمی صورت نگرفته‌است. بلکه به نیازهای واقعی و از این رو نیروهای اقتصادی پرداخته شده‌است. استفاده از آن برای برنامه‌های غیر امنیتی مانند بهره‌وری عملیاتی، نقشه‌برداری حرارتی خریداران از مناطق نمایش (به معنای تعداد افراد در یک منطقه خاص در یک فضای خرده فروشی) و حضور در کلاس‌ها در حال استفاده است. انسان‌ها برای جمع‌آوری و تشخیص الگوهای متشکل از مجموعه داده‌های بسیار بزرگ که نیاز به محاسبات همزمان در چندین مکان مشاهده شده از راه دور دارند، به اندازه هوش مصنوعی نیستند. هیچ انسان بومی در مورد چنین آگاهی وجود ندارد. نشان داده شده‌است که چندین وظیفه همزمان توجه و عملکرد انسان را نامتمرکز می‌کند. هوش مصنوعی توانایی مدیریت چنین داده‌هایی را دارد. برای هدف تعامل امنیتی با دوربین‌های فیلمبرداری، از نظر عملکردی، از دید بینایی بهتری نسبت به انسان یا تقریب دستگاه با آن برخوردار هستند. برای قضاوت در مورد ظرافت رفتارها یا اهداف افراد یا درجات تهدید، انسان‌ها در وضعیت فعلی این فناوری بسیار برتر هستند؛ بنابراین هوش مصنوعی در عملکردهای امنیتی به‌طور گسترده‌ای فراتر از توانایی انسانی را اسکن می‌کند و داده‌ها را در اولین مرتبه از مرتب‌سازی ارتباط بررسی می‌کند و به افسر انسانی که عملکرد ارزیابی و پاسخ را بر عهده دارد، هشدار می‌دهد.
امنیت در دنیای عملی از نظر اقتصادی تعیین می‌شود به طوری که هزینه‌های امنیت پیشگیرانه هرگز به‌طور معمول از هزینه‌های قابل قبول ریسکی که باید اجتناب شود، فراتر نمی‌رود. مطالعات نشان داده‌است که شرکت‌ها معمولاً فقط یک بیست و پنجم مبلغی را که ضررهای واقعی آن‌ها برایشان هزینه دارد برای امنیت خرج می‌کنند. آنچه با نظریه اقتصادی خالص باید معادل باشد، بنابراین بسیار کوتاهتر از آن است. نظریه ای که این مسئله را توضیح می‌دهد ناهماهنگی شناختی یا سهولتی که باعث می‌شود چیزهای ناخوشایند مانند خطر، از ذهن آگاه دور شود. با این وجود، امنیت یک هزینه بزرگ است و مقایسه هزینه‌های مختلف ابزارهای امنیتی همیشه در بین متخصصان امنیتی، مهمترین است.
دلیل دیگر اینکه تهدیدات یا خسارات امنیتی آینده کمتر مورد ارزیابی قرار می‌گیرند این است که غالباً فقط هزینه مستقیم خسارت احتمالی به جای طیف ضررهای پی در پی که همزمان تجربه می‌شوند در نظر گرفته می‌شود. به عنوان مثال، تخریب خرابکارانه یک ماشین تولید سفارشی در یک کارخانه یا یک تریلر یخچالی منجر به زمان تعویض طولانی مدت می‌شود که در طی آن امکان سرویس دهی به مشتریان وجود ندارد و در نتیجه تجارت آن‌ها از بین می‌رود. یک جُرم خشن، فراتر از مسئولیت مستقیم ناشی از عدم حمایت از کارگر، موجب خسارت گسترده روابط عمومی برای یک کارفرما خواهد شد.
تجزیه و تحلیل رفتاری منحصر به فرد، عملکردی فراتر از امنیت ساده دارد و به دلیل توانایی آن در مشاهده نقض الگوهای استاندارد پروتکل‌ها، می‌تواند به‌طور مؤثری اقدامات ناامن کارمندان را که منجر به حوادث ناشی از مسئولیت عمومی یا مسئولیت کارگران می‌شود، پیدا کند. در اینجا نیز ارزیابی هزینه‌های حوادث آینده با واقعیت فاصله دارد. یک مطالعه توسط شرکت بیمه لیبرتی میچوال نشان داد که هزینه کارفرمایان حدود شش برابر هزینه بیمه شده مستقیم است، زیرا هزینه‌های بیمه نشده خسارت‌های ناشی از آن شامل کارگران جایگزین موقت، هزینه‌های استخدام برای جایگزین‌ها، هزینه‌های آموزش، وقت مدیران در گزارش‌ها یا دادگاه، روحیه نامطلوب سایر کارگران، و تأثیر بر مشتری و روابط عمومی است. پتانسیل هوش مصنوعی در قالب تجزیه و تحلیل رفتاری برای رهگیری و پیشگیری از وقوع چنین حوادثی قابل توجه است.
