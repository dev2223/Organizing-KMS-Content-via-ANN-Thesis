یکی از کاربردهای بالقوه استفاده از هوش مصنوعی از بین بردن خطرات با حذف انسان ها از موقعیت های خطرناک است که ریسک استرس، کار بیش از حد یا آسیب های اسکلتی عضلانی را شامل می شوند. همچنین می توان از تحلیل‌های پیش‌بینی‌کننده برای شناسایی شرایطی استفاده کرد که ممکن است منجر به خطراتی مانند خستگی، آسیب‌های فشاری مکرر یا قرار گرفتن در معرض مواد سمی شود که منجر به مداخلات زودتر شود. یکی دیگر از این موارد، ساده‌سازی گردش‌های کاری ایمنی و سلامت محیط کار از طریق خودکار کردن وظایف تکراری، افزایش برنامه‌های آموزشی ایمنی از طریق واقعیت مجازی، یا شناسایی و گزارش مواردی که نیاز به تماس نزدیک دارند.
زمانی که هوش مصنوعی در محل کار استفاده می شود، احتمال خطرات جدیدی را نیز شامل می شود. این خطرات ممکن است ناشی از تکنیک‌های یادگیری ماشینی باشند که منجر به رفتار غیرقابل پیش‌بینی و غیر قابل تشخیص در تصمیم‌گیری هوش مصنوعی می‌شود، یا از مسائلی مانند امنیت رایانه و حریم خصوصی اطلاعات نشات بگیرد.بسیاری از خطرات هوش مصنوعی به دلیل پتانسیل آن برای ایجاد تغییرات در محل کار ، روانی - اجتماعی هستند. این خطرات شامل تغییر در مهارت های مورد نیاز کارگران، افزایش نظارت منجر به مدیریت خرد ، الگوریتم هایی که به طور ناخواسته یا عمدی از تعصب های نامطلوب انسانی تقلید می کنند و در عوض مقصر دانستن  اپراتور انسانی به جای خطاهای ماشین است. هوش مصنوعی همچنین ممکن است به خطرات فیزیکی مانند برخورد انسان و ربات و خطرات ارگونومی رابط های کنترلی و تعاملات انسان و ماشین منجر شود. کنترل‌های خطر شامل اقدامات امنیت رایانه ای و حفظ حریم خصوصی اطلاعات، ارتباط و شفافیت با کارگران در مورد استفاده از داده‌ها و محدودیت‌های روی همرُبات ها است.
از منظر ایمنی و سلامت محل کار، تنها هوش مصنوعی «ضعیف» یا «باریک» که برای یک کار خاص طراحی شده است مناسب است، بخاطراینکه نمونه‌های زیادی  در حال حاضر در حال استفاده هستند یا در آینده نزدیک  انتظار می‌رود مورد استفاده قرار گیرند. هوش مصنوعی «قوی» یا «جامع»  در آینده نزدیک انتظار نمی رود که قابل اجرا باشد و بحث در مورد خطرات استفاده از آن به جای متخصصان بهداشت صنعتی در حیطه اختیارات آینده پژوهان و فیلسوفان است.
برای اینکه هر برنامه بالقوه مرتبط با سلامت و ایمنی هوش مصنوعی پذیرفته شود، نیاز به پذیرش از سوی مدیران و کارکنان دارد. برای مثال، پذیرش کارگران ممکن است به دلیل نگرانی در مورد حفظ حریم خصوصی اطلاعات،  یا عدم اعتماد و پذیرش فناوری جدید، که ممکن است از شفافیت یا آموزش ناکافی ناشی شود، تقلیل یابد. &#58;&#8202;26–28,&#8202;43–45&#8202;
از طرف دیگر، مدیران ممکن است در هنگام پیاده‌سازی سامانه‌های مبتنی بر هوش مصنوعی، به جای افزایش ایمنی و سلامت کارگران بر افزایش بهره‌وری اقتصادی  اهمیت بدهند.
هوش مصنوعی ممکن است دامنه وظایف کاری را افزایش دهد که در آن می توان یک کارگر را از موقعیتی که خطر دارد مصون نگه داشت. به یک معنا، در حالی که خودکارسازی سنتی می تواند عملکردهای بدن کارگر را با یک ربات جایگزین کند، هوش مصنوعی به طور موثری عملکردهای مغز آنها را با رایانه جایگزین می کند. خطراتی که می توان از آنها اجتناب کرد عبارتند از استرس، کار بیش از حد، آسیب های اسکلتی عضلانی و بی حوصلگی.  &#58;&#8202;5–7&#8202;
این می تواند دامنه بخش های شغلی آسیب دیده را به مشاغل یقه سفید و خدماتی مانند پزشکی، مالی و فناوری اطلاعات گسترش دهد.  به عنوان مثال، کارکنان مرکز تماس به دلیل ماهیت تکراری و سخت و نرخ بالای نظارت خرد با خطرات سلامت و ایمنی گسترده ای روبرو هستند. ربات های مکالمه مجهز به هوش مصنوعی نیاز انسان به انجام اولیه ترین وظایف مرکز تماس را کاهش می دهند.  &#58;&#8202;5–7&#8202;
یادگیری ماشین برای تجزیه و تحلیل افراد استفاده می شود تا پیش بینی هایی در مورد رفتار کارگران مانند استخدام و ارزیابی عملکرد انجام دهد تا به تصمیم گیری مدیریت کمک کند. این تجزیه و تحلیل ها همچنین می تواند برای بهبود سلامت کارگران استفاده شوند. تجزیه و تحلیل ممکن است بر اساس ورودی هایی مانند فعالیت های آنلاین، نظارت بر ارتباطات، ردیابی مکان،  تجزیه و تحلیل صدا و  تجزیه و تحلیل زبان بدن از مصاحبه های فیلمبرداری شده باشد. به عنوان مثال، تجزیه و تحلیل احساسات ممکن است برای تشخیص خستگی برای جلوگیری از کار بیش از حد استفاده شود.  &#58;&#8202;3–7&#8202; به عنوان مثال سامانه های پشتیبانی تصمیم توانایی مشابهی برای جلوگیری از فاجعه های صنعتی یا کارآمدتر کردن واکنش به بلایا دارند.
برای کارگران جابجا کننده دستی مواد، تحلیل پیشگویانه و هوش مصنوعی ممکن است برای کاهش آسیب اسکلتی عضلانی استفاده شود. دستورالعمل‌های سنتی بر اساس میانگین‌های آماری برای انسان‌های معمولی از نظر انسان سنجی طراحی شده اند. تجزیه و تحلیل مقادیر زیادی از داده‌های حسگرهای پوشیدنی ممکن است امکان محاسبه شخصی و بلادرنگ ریسک ارگونومی و مدیریت خستگی و همچنین تجزیه و تحلیل بهتر ریسک مرتبط با نقش‌های شغلی خاص را فراهم کند. 
حسگرهای پوشیدنی همچنین ممکن است مداخله زودهنگام در برابر قرار گرفتن در معرض مواد سمی را نسبت به آزمایش منطقه یا ناحیه تنفسی به صورت دوره ای امکان پذیر کنند. علاوه بر این، مجموع دادگان های بزرگ تولید شده می تواند نظارت بر سلامت محل کار، ارزیابی ریسک و تحقیقات را بهبود بخشد. 
از هوش مصنوعی  همچنین می‌توان برای کارآمدتر کردن ایمنی و سلامت محیط در گردش کار  بهره برد. یک مثال، کدگذاری مطالبات غرامت کارگران  است که به صورت متنی ارائه می شود و باید به صورت دستی کدهای استاندارد شده به آنها اختصاص داده شود. هوش مصنوعی برای انجام سریع‌تر، ارزان‌تر و با خطاهای کمتر در حال بررسی است.  
ممکن است از هوش مصنوعی برای شناسایی موثرتر مواردی که نیاز به تماس نزدیک دارند استفاده شود. گزارش و تجزیه و تحلیل حوادث تماس نزدیک در کاهش میزان حادثه ها مهم هست، اما اغلب کمتر گزارش می شود زیرا توسط انسان مورد توجه قرار نمی گیرد یا بخاطر عوامل اجتماعی توسط کارگران گزارش نمی شود. 
چندین جنبه گسترده از هوش مصنوعی وجود دارد که ممکن است منجر به خطرات خاصی شود. این خطرات علاوه بر حضور هوش مصنوعی به پیاده سازی نیز بستگی دارد.  &#58;&#8202;2–3&#8202;
سامانه هایی که از هوش مصنوعی فرعی نمادین مانند یادگیری ماشین استفاده می‌کنند ممکن است غیرقابل پیش‌بینی رفتار کنند و در تصمیم‌گیری‌هایشان بیشتر مستعد تفحص ناپذیری هستند.
این امر به ویژه در صورتی صادق است که با موقعیتی مواجه شوید که بخشی از مجموعه داده های آموزشی هوش مصنوعی در دسترس نبوده و همچنین در محیط هایی که ساختار کمتری دارند تشدید می شود.
رفتار نامطلوب ممکن است از نقص در ادراک سامانه (که از درون نرم افزار یا خرابی حسگر ناشی می شود)، بازنمود دانش یا از اشکالات نرم افزاری ناشی شود.  &#58;&#8202;14–18&#8202; همچنین این رفتار نامطلوب ممکن است از آموزش نامناسب نیز ناشی شود، مانند استفاده از الگوریتم مشابه توسط کاربر برای دو مشکل که الزامات یکسانی ندارند.  &#58;&#8202;12–13&#8202;یادگیری ماشینی که در مرحله طراحی اعمال می‌شود ممکن است پیامدهای متفاوتی نسبت به آنچه در زمان اجرا اعمال می‌شود داشته باشد. سامانه هایی که از هوش مصنوعی نمادین استفاده می کنند کمتر مستعد رفتار غیرقابل پیش بینی هستند.  &#58;&#8202;14–18&#8202;
استفاده از هوش مصنوعی همچنین خطرات امنیت رایانه ای را نسبت به پلتفرم هایی که از هوش مصنوعی استفاده نمی کنند، افزایش می دهد  و نگرانی های مرتبط با حریم خصوصی اطلاعات در مورد داده های جمع آوری شده ممکن است برای کارگران مشکل ایجاد کند. 
مخاطرات روانی - اجتماعی مواردی هستند که از نحوه طراحی، سازماندهی و مدیریت کار یا زمینه های اقتصادی و اجتماعی آن ناشی می شوند، نه اینکه از یک ماده یا شیء فیزیکی ناشی شوند.آنها نه تنها باعث پیامد های روانی مانند فرسودگی شغلی، اختلالات اضطرابی و افسردگی می شوند، بلکه می توانند باعث آسیب های جسمی مانند آسیب عضلانی اسکلتی  یا بیماری هایی مانند بیماری های قلبی عروقی نیز شوند.  
بسیاری از خطرات هوش مصنوعی به دلیل پتانسیل ایجاد تغییرات در سازمان کار، از نظر افزایش پیچیدگی و تعامل بین عوامل مختلف سازمانی، ماهیت روانی - اجتماعی دارند. با این حال، خطرات روانی اجتماعی اغلب توسط طراحان سامانه های تولید پیشرفته نادیده گرفته می شوند. 
انتظار می‌رود هوش مصنوعی منجر به تغییراتی در مهارت‌های مورد نیاز کارگران شود که مستلزم آموزش کارگران، انعطاف‌پذیری و گشودگی در برابر تغییر است. نیاز به ترکیب تخصص مرسوم با مهارت های کامپیوتری ممکن است برای کارگران موجود چالش برانگیز باشد.  اتکای بیش از حد به ابزارهای هوش مصنوعی ممکن است منجر به مهارت زدایی در برخی از حرفه ها شود. 
افزایش نظارت ممکن است به مدیریت خرد و در نتیجه منجر به استرس و اضطراب شود. درک نظارت نیز ممکن است منجر به استرس شود. کنترل‌های این موارد شامل مشاوره با گروه‌های کارگری، آزمایش‌های گسترده و توجه به سوگیری معرفی‌شده است. حسگرهای پوشیدنی، ردیاب‌های فعالیت و واقعیت افزوده نیز ممکن است منجر به استرس ناشی از مدیریت خرد، هم برای کارگران خط مونتاژ و هم برای پیمانکاران مستقل شود. همچنین پیمانکاران مستقل فاقد حقوق و حمایت قانونی کارگران رسمی هستند.  &#58;&#8202;2–10&#8202;
همچنین این خطر وجود دارد که افراد مجبور شوند با سرعت یک روبات کار کنند یا عملکرد ربات را در ساعات غیر استاندارد نظارت کنند.  &#58;&#8202;5–7&#8202;
&#160; الگوریتم هایی که بر روی تصمیمات گذشته آموزش دیده اند ممکن است تعصب های نامطلوب انسانی را تقلید کنند، شیوه های استخدام تبعیض آمیز و اخراج هایی  که درگذشته رخ داده اند را می توان مثال زد. عدم تقارن اطلاعات بین مدیریت و کارکنان ممکن است منجر به استرس شود، اگر کارگران به داده ها یا الگوریتم هایی که مبنای تصمیم گیری هستند دسترسی نداشته باشند.  &#58;&#8202;3–5&#8202;
علاوه بر ساخت مدلی با ویژگی‌های ناخواسته تبعیض‌آمیز، تبعیض عمدی ممکن است از طریق طراحی معیارهایی رخ دهد که مخفیانه منجر به تبعیض از طریق متغیرهای همبسته به روشی غیر آشکار می‌شود.  &#58;&#8202;12–13&#8202;
در فعل و انفعالات پیچیده انسان و ماشین، برخی از رویکردها برای تجزیه و تحلیل تصادف ممکن است برای محافظت از یک سامانه فناوری و توسعه دهندگان آن با مقصر دانستن یک اپراتور انسانی به جای آن، تعصب داشته باشند. 
خطرات فیزیکی  ممکن است از روبات‌هایی که از هوش مصنوعی استفاده می‌کنند، به شکل برخورد انسان و ربات، به‌ویژه روبات‌های مشارکتی (همبات) ناشی شوند. همبات ها برای کار در نزدیکی انسان‌ها در نظر گرفته شده‌اند که کنترل خطر رایج جداسازی ربات با استفاده از نرده‌ها یا موانع دیگر را غیر ممکن میکند، که به طور گستده برای روبات‌های صنعتی سنتی استفاده می‌شود. وسایل نقلیه هدایت شونده خودکار نوعی همبات هستند که از سال 2019 معمولاً به عنوان لیفتراک یا جک پالت در انبارها یا کارخانه ها استفاده می شوند. در همبات ها، نقص سنسور یا شرایط محیط کار غیرمنتظره می تواند منجر به رفتار غیرقابل پیش بینی ربات و در نتیجه برخورد انسان و ربات شود.  &#58;&#8202;5–7&#8202;
اتومبیل های خودران نمونه دیگری از ربات های مجهز به هوش مصنوعی هستند. علاوه بر این، ارگونومی رابط های کنترل و تعاملات انسان و ماشین ممکن است خطراتی را ایجاد کند. 
هوش مصنوعی، مشابه با سایر فناوری‌های محاسباتی، به اقدامات امنیت رایانه ای برای جلوگیری از نقض‌ها و نفوذهای نرم‌افزاری &#58;&#8202;17&#8202; و همچنین اقدامات حفظ حریم خصوصی اطلاعات نیاز دارد.
ارتباط و شفافیت با کارگران در مورد استفاده از داده ها کنترلی برای خطرات روانی اجتماعی ناشی از مسائل امنیتی و حریم خصوصی است.  بهترین شیوه‌های پیشنهادی برای برنامه‌های نظارت بر کارگران تحت حمایت کارفرما شامل استفاده از فناوری‌های حسگر معتبر، تضمین مشارکت داوطلبانه کارگران، توقف جمع آوری داده ها در خارج از محل کار، افشای تمام موارد استفاده از داده ها و اطمینان از ذخیره سازی امن داده ها است. 
سازمان بین‌المللی استاندارد (ISO) برای همبات های صنعتی مجهز به حسگرهای مجهز به هوش مصنوعی توصیه های زیر را می‌کند: (الف) کنترل‌های توقف نظارت شده مرتبط با ایمنی؛ (ب) هدایت همبات با دست انسان؛ ج) کنترل‌های نظارت بر سرعت و جداسازی. و (د) محدودیت های قدرت و نیرو. ربات‌های مجهز به هوش مصنوعی شبکه‌ای ممکن است پیشرفت‌های ایمنی را با یکدیگر به اشتراک بگذارند.  نظارت انسانی یکی دیگر از کنترل‌های خطر عمومی برای هوش مصنوعی است.  &#58;&#8202;12–13&#8202;
هم کاربردها و هم خطرات ناشی از هوش مصنوعی را می توان به عنوان بخشی از چارچوب های موجود برای مدیریت ریسک ایمنی و بهداشت شغلی در نظر گرفت. همانند تمام خطرات، شناسایی ریسک زمانی که در مرحله طراحی انجام می شود، موثرترین و کم هزینه ترین است. 
نظارت بر سلامت محل کار ، جمع‌آوری و تجزیه و تحلیل داده‌های بهداشتی کارگران، برای هوش مصنوعی چالش برانگیز است، زیرا داده‌های نیروی کار اغلب به صورت انبوه گزارش می‌شوند و تفکیک بین انواع مختلف کار را ارائه نمی‌دهند و به جای محتوای مهارتی مشاغل، بر داده های اقتصادی مانند دستمزد و نرخ اشتغال متمرکز هستند.  پروکسی‌های محتوای مهارتی شامل الزامات آموزشی و طبقه‌بندی مشاغل معمولی در مقابل غیر معمول و شناختی در مقابل کارهای فیزیکی است. با این حال، ممکن است هنوز به اندازه کافی مشخص نباشند تا مشاغل خاصی را که دارای تأثیرات متمایز از هوش مصنوعی هستند تشخیص دهند. شبکه اطلاعات شغلی وزارت کار ایالات متحده نمونه ای از پایگاه داده با طبقه بندی دقیق مهارت ها است. علاوه بر این، داده ها اغلب در سطح ملی گزارش می شوند، در حالی که تنوع جغرافیایی زیادی، به ویژه بین مناطق شهری و روستایی وجود دارد. 
&#160; از سال 2019، ISO در حال توسعه استانداردی برای استفاده از معیارها و کارپوشه ها، نمایشگرهای اطلاعاتی است که معیارهای شرکت را برای مدیران در محل کار ارائه می دهد.این استاندارد برنامه ریزی شده است که شامل دستورالعمل هایی برای جمع آوری داده ها و نمایش آنها به شیوه ای قابل مشاهده و مفید باشد.&#58;&#8202;11&#8202;
در اتحادیه اروپا ، مقررات عمومی حفاظت از داده ها ، در حالی که به داده های مصرف کننده گرایش دارد، برای جمع آوری داده های محل کار نیز مرتبط است. موضوع داده‌ها، از جمله کارگران، «حق این را دارند که تحت تصمیم‌گیری صرفاً بر اساس پردازش خودکار قرار نگیرند». سایر دستورالعمل های اتحادیه اروپا شامل دستورالعمل ماشین آلات (2006/42/EC)، دستورالعمل تجهیزات رادیویی (2014/53/EU) و دستورالعمل ایمنی محصول عمومی (2001/95/EC) است.  &#58;&#8202;10,&#8202;12–13&#8202;
