آزمایش تورینگ (به انگلیسی&#58; Turing test)، با نام اصلی بازی تقلید، توسط آلن تورینگ و در سال ۱۹۵۰ معرفی شد، این آزمایش دربارهٔ توانایی یک ماشین برای ارائه رفتارهای هوشمندانه برابر یا غیرقابل تمایز از رفتارهای یک انسان است. تورینگ پیشنهاد کرد که یک ارزیابی کننده انسانی گفتگوی زبان طبیعی بین یک انسان و یک ماشین که قصد تولید پاسخ‌های شبه انسانی دارد، را قضاوت نماید. ارزیابی کننده فقط از این موضوع اطلاع دارد که یکی از دو شریک در گفتگو یک ماشین است و همه مشارکت کننده‌ها از یکدیگر تفکیک شده‌اند. این گفتگو فقط به کانال متنی محدود است، مثل یک کیبرد و نمایشگر رایانه‌ای، از این رو نتایج به توانایی ماشین برای ارائه کلمات به صورت گفتار بستگی ندارد. در اینجا اگر ارزیابی کننده نتواند ماشین را از انسان تشخیص دهد، گفته می‌شود که ماشین آزمایش را پشت سر گذاشته‌است (پاس کرده‌است). نتایج این آزمایش به توانایی ماشین برای تحویل جواب‌های صحیح به سوالات بستگی ندارد، یعنی فقط به این بستگی دارد که چقدر جواب‌ها با جواب‌هایی که یک انسان می‌دهد شباهت دارد و نزدیک است.
این آزمایش در مقاله‌ای در سال ۱۹۵۰ توسط آلن تورینگ با عنوان «ماشین رایانش و هوش Computing Machinery and Intelligence» معرفی شد، تورینگ در آن موقع در دانشگاه منچستر کار می‌کرد. تورینگ اینچنین شروع می‌کند: «پیشنهاد می‌کنم که این سؤال را درنظر بگیرید "آیا ماشین‌ها می‌توانند فکر کنند؟"». اما به دلیل آنکه تعریف واژه «فکر کردن» بسیار سخت است، تورینگ تصمیم گرفت که "سوال را با سوال دیگری جایگزین کند، که با آن بسیار مرتبط بود اما توسط واژه‌های نسبتا غیرمبهم بیان شده بود". تورینگ حالت جدید مسئله را در قالب بازی سه نفره، که «بازی تقلید» نامیده می‌شد توصیف کرد، که در آن یک بازپرس از یک مرد و یک زن در اتاق دیگر سوالاتی می‌پرسید تا تعیین کند که جنسیت صحیح دو بازیگر چیست. سؤال جدید تورینگ این بود: «آیا رایانه دیجیتال قابل تصوری وجود دارد که در بازی تقلید به خوبی عمل کند؟» تورینگ معتقد بود که این سؤال واقعاً قابل جوابگویی است. تورینگ در ادامه مقاله‌اش دربارهٔ انتقادات اصلی به این گزاره که «ماشین‌ها می‌توانند فکر کنند» به بحث پرداخته‌است.
به دلیل آنکه تورینگ اول این آزمایش را معرفی کرد، اثبات شده‌است که هم بسیار بانفوذ و هم بسیار انتقادی است، و به یک مفهوم مهم در فلسفه هوش مصنوعی تبدیل شده‌است. بعضی از این انتقادات، مثل اتاق چینی جان سرل، خودشان بحث‌برانگیز هستند.
آزمون تورینگ روشی برای سنجش میزان هوشمندی ماشین است. آزمون به این صورت انجام می‌گیرد که یک شخص به عنوان آزمایشگر، با یک ماشین و یک انسان به گفتگو می‌نشیند، و سعی در تشخیص ماشین از انسان دارد. در صورتی که ماشین بتواند قاضی را به گونه‌ای بفریبد که در قضاوت خود دچار اشتباه شود، توانسته‌است آزمون را با موفقیت پشت سر بگذارد. برای اینکه تمرکز آزمون بر روی هوشمندی ماشین باشد، و نه توانایی آن در تقلید صدای انسان، مکالمه تنها از طریق متن و صفحه کلید و نمایشگر کامپیوتر صورت می‌گیرد.
این سوال که آیا ماشین ها می¬توانند فکر کنند یا خیر سابقه ای طولانی دارد که در تمایز دیدگاه های دوگانه گرایانه و مادی گرایانه ذهن محکم رسوخ کرده است. رنه دکارت جنبه هایی از آزمون تورینگ را در مقاله ی «Discourse on the Method» در سال 1637 بیان کرده است:  چگونه می توان بسیاری از اتوماتا های مختلف و یا ماشین آلات در حال حرکت را توسط صنعت انسان ساخت... زیرا که ما به راحتی می توانیم اجزای تشکیل دهنده ی یک ماشین را که می¬تواند تکلم کند را تشخیص دهیم، و حتی اعمالی فیزیکی را در پاسخ به آن انجام دهیم، که تغییر در اندامش را سبب خواهد شد؛ به عنوان مثال، اگر یک بخش خاص آن را لمس کنیم ممکن است بپرسید چه کاری را از او می خواهیم؛ اگر بخش دیگری را لمس کنیم ممکن است اعلام کند که دردش می¬گیرد، و مانند آن. اما هرگز اتفاق نمی افتد که سخنرانی خود را به روش های مختلف ترتیب دهد، تا به هر کاری که ممکن است در حضورش گفته شود پاسخ مناسب دهد، چرا که حتی پایین ترین نوع انسان می تواند آن را انجام دهد.[10] در اینجا دکارت اشاره می کند که اتوماتا قادر به پاسخ دادن به تعاملات انسانی است اما استدلال می کند که چنین اتوماتا هایی نمی توانند به چیزهایی که در حضور شان گفته می شود، به گونه ای که هر انسانی می تواند، پاسخ مناسبی دهند. بنابراین دکارت آزمون تورینگ را با تعریفِ نارسایی پاسخ زبانی مناسب به عنوان آن که انسان را از اتوماتون جدا می کند، پیش می گیرد. دکارت نتوانست این احتمال را در نظر بگیرد که اتوماتای آینده ممکن است بتواند بر چنین نارسایی هایی غلبه کند و آزمون تورینگ را به این ترتیب پیشنهاد نمی کند، حتی اگر چارچوب و معیار مفهومی آن را پیش بینی کند. دنیس دیدروت در فلسفه پنسه  خود یک معیار آزمون-تورینگ فرموله می کند: "اگر طوطی پیدا کنند که بتواند به همه چیز پاسخ دهد، من بدون تردید ادعا می کردم که یک وجود باهوش است." [11] این به این معنا نیست که او با این موضوع موافق است، بلکه این عبارت استدلال مشترک مادی گرایان در آن زمان بوده است.بر اساس دوگانگی، ذهن غیر فیزیکی است (یا حداقل، خواص غیر فیزیکی دارد)[۱۲] و بنابراین، نمی توان آن را به صورت صرفاً فیزیکی توضیح داد. با توجه به ماده گرایی، ذهن را می توان به صورت فیزیکی توضیح داد که امکان وجود ذهن هایی که به صورت مصنوعی تولید می شوند را باز می¬کند. [13] در سال ۱۹۳۶ فیلسوفی به نامِ آلفرد آیر پرسش فلسفی استاندارد ذهن های دیگر را در نظر گرفت: از کجا بدانیم که افراد دیگر همان تجربه های آگاهانه ای را دارند که ما داریم؟ آیر در کتاب خود به نام زبان، حقیقت و منطق پروتکلی را برای تمایز بین یک انسان آگاه و یک ماشین ناخودآگاه پیشنهادکرد: «تنها زمینه ای که می توانم برای اظهار این موضوع داشته باشم که شیء¬ای که به نظر می رسد هوشیار است، واقعاً یک وجود آگاهانه نیست، بلکه تنها یک ساختگی یا یک ماشین است، این است که نتواند یکی از آزمایش های تجربی را انجام دهد که به کمک آن حضور یا عدم آگاهی مشخص می شود.» [14] (این پیشنهاد بسیار شبیه به آزمون تورینگ است، اما به هوشیاری مربوط می شود تا هوش. گذشته از این، مسلم نیست که فلسفه کلاسیک محبوب آیر برای تورینگ آشنا بوده است.) به عبارت دیگر، یک چیز آگاه نیست اگر در آزمون آگاهی شکست بخورد.
محققان در بریتانیا تا ده سال پیش از تأسیس رشته تحقیقات هوش مصنوعی در سال ۱۹۵۶ در حال کاوش در «هوش ماشینی»بودند. [15]  این موضوع مشترک در میان اعضای باشگاه نسبت بود - یک گروه غیر رسمی از محققان سایبرنتیک و الکترونیک بریتانیا که شامل آلن تورینگ بود. [16] تورینگ، به ویژه، حداقل از سال ۱۹۴۱[۱۷] درگیر فکر مفهوم هوش ماشینی بود و یکی از اولین ذکر های شناخته شده از «هوش کامپیوتری» توسط او در سال ۱۹۴۷ ساخته شد. [۱۸] در گزارش تورینگ، "ماشین آلات هوشمند"،[۱۹]  او به بررسی «این سوال که آیا امکان نشان دادن رفتار هوشمندانه برای ماشین آلات وجود دارد یا نه»[۲۰] پرداخت ؛ و به عنوان بخشی از آن تحقیق، آنچه را که ممکن است مقدمه آزمایش های بعدی او محسوب شود، پیشنهاد کرد: ابداع یک ماشین کاغذی که بازی نه چندان بد شطرنج را انجام خواهد داد کار سختی نیست. [21] حال سه مرد الف، ب و ج را به عنوان سوژه برای آزمایش در نظر بگیرید. الف و ج را به جای بازیکنان ضعیف شطرنج در نظر بگیرید، و ب مسئولی است که با ماشین کاغذی کار می کند. ... از دو اتاق با تدارکات مشخصی برای برقراری ارتباط استفاده می شود، و یک بازی بین ج و یا الف یا ماشین کاغذ انجام می شود. ممکن است تعیین این که دارد با الف بازی می¬کند یا با ماشین کاغذی برای ج کاملا دشوار باشد. [22] "ماشین آلات محاسبات و هوش"(۱۹۵۰)اولین مقاله منتشر شده توسط تورینگ بود که در آن منحصراً بر روی هوش ماشینتمرکز کرد. تورینگ مقاله سال ۱۹۵۰ را با این ادعا آغاز می کند، «من پیشنهاد می کنم این سوال را در نظر بگيریم که آیا ماشین ها می توانند فکر کنند؟ '  [5] همانطور که او خاطر نشان کرد، رویکرد سنتی به چنین سوالی این است که با تعاریف هر دو اصطلاح "ماشین" و""هوش" شروع کنیم. تورینگ انتخاب می کند که این کار انجام ندهد؛ در عوض او سوال را با سوال جدیدی جایگزین می کند که «ارتباط نزدیکی با آن دارد و با کلمات نسبتاً بدون ابهام بیان می شود.» [۵] در واقع او پیشنهاد می کند که این سوال را از «آیا ماشین ها می توانند فکر کنند؟» به «آیا ماشین ها می توانند کاری را انجام دهند که ما (به عنوان نهادهای تفکر) می توانیم انجام دهیم؟» [۲۳] تورینگ استدلال می کند که مزیت پرسش جدید، ، این است که «خط نسبتاً دقیقی بین توان های جسمی و فکری یک انسان» ترسیم می کند. [24] برای نشان دادن این رویکرد تورینگ آزمونی را پیشنهاد می کند که از یک بازی مهمانی الهام گرفته شده است که به «بازی تقلیدی» معروف است و در آن یک مرد و یک زن به اتاق های جداگانه ای می روند و مهمانان سعی می کنند با نوشتن یک سری پرسش ها و خواندن پاسخ های تایپی ارسال شده آن ها را از هم تشخیص دهند. در این بازی هم مرد و هم زن هدفش متقاعد کردن مهمانان است که دیگری هستند. (هوما شاه استدلال می کند که این نسخه دو انسانی از بازی توسط تورینگ تنها برای معرفی خواننده به آزمون پرسش و پاسخِ ماشین-انسان ارائه شده است. [25]) تورینگ نسخه جدید خود از این بازی را این طور توصیف کرد: اکنون این سوال را می پرسیم که «وقتی یک ماشین در این بازی به عنوان بخشی از الف عمل کند چه اتفاقی خواهد افتاد؟» آیا بازجو همانند و با همان نرخ به اشتباه تصمیم خواهد گرفت که وقتی بازی این طور انجام می شود در مقابل زمانی که بازی بین یک مرد و یک زن انجام می شود؟ این سوالات جایگزین اصلی ما می شوند، "آیا ماشین ها می توانند فکر کنند؟" [24] بعدها در مقاله تورینگ یک فرمول بندی جایگزین "معادل" را پیشنهاد می کند که شامل یک قاضی است که تنها با یک کامپیوتر و یک انسان طرف است.[۲۶] در حالی که هیچ یک از این فرمول بندی ها دقیقاً با نسخه آزمون تورینگ که امروزه به طور کلی تر شناخته شده است مطابقت ندارد، او یک آزمون سوم را نیز در سال ۱۹۵۲ پیشنهاد کرد.  در این نسخه که تورینگ در یک پخش رادیویی بی بی سی به آن پرداخت، یک هیئت منصفه سوالاتی از یک کامپیوتر می پرسد و نقش کامپیوتر این است که بخش قابل توجهی از هیئت منصفه بر این باورند که واقعا ً یک انسان است. [27] مقاله تورینگ ۹ مورد عمده را در نظر گرفت که شامل تمام استدلال های علیه هوش مصنوعی است که در سال های پس از انتشار مقاله مطرح شده است (رجوع کنید به "ماشینآلات محاسباتی و هوش"). [6]
در سال ۱۹۶۶ جوزف ویزنبام برنامه ای ایجاد کرد که به نظر می رسید آزمون تورینگ را پشت سر می نهد. این برنامه که با نام ELIZA شناخته می شود با بررسی نظرات تایپ شده یک کاربر برای کلمات کلیدی کار میکرد. اگر یک کلمه کلیدی پیدا شود، قاعده ای که نظرات کاربر را منتقل می دهد جایگزین می شود، و جمله حاصل برمی گردد. اگر کلمه کلیدی یافت نشد، ELIZA یا با یک جواب عمومی یا با تکرار یکی از نظرات قبلی پاسخ می دهد. [28] علاوه بر این ، ویزنبام نسخه دیگری از ELIZA را که برای تقلید رفتار یک روانشناس راجری بود را توسعه داد، که به ELIZA اجازه می دهد آزادانه با فرض دانستن تقریبا هیچ چیز از جهان واقعی عمل کند. [29] با این تکنیک ها ، برنامه ویزنبام قادر بود برخی از مردم را گول گول بزند که آنها در حال صحبت کردن با یک فرد واقعی هستند [29] بنابراین ، برخی ادعا کردند که یکی از برنامه ها (شاید اولی) قادر به پاس شدن آزمون تورینگ هست،[29][30] حتی اگر در این دیدگاه نزاع بسیار باشد (اینجا را نگاه کنید). کنت کولبی در سال ۱۹۷۲ PARRY را ایجاد کرد، برنامه ای که به عنوان "ELIZA¬ی با نگرش" توصیف شد. [31]   که تلاشی برای مدل کردن رفتار یک بیمار اسکیزوفرنی پارانویید بود، که از رویکردی مشابه (حتی پیشرفته تر) رویکردی که ویزنبام داشت، استفاده می¬کرد. برای اعتبار بخشیدن به کار، PARRY در اوایل دهه ۱۹۷۰ با استفاده از انواع آزمون های تورینگ مورد آزمایش قرار گرفت. گروهی از روانپزشکان با تجربه ترکیبی از بیماران واقعی و رایانه هایی را که PARRY را اجرا می¬کردند، مورد تجزیه و تحلیل قرار دادند. متن مکالمات را به گروه دیگری شامل ۳۳ روانپزشک نشان دادند. سپس از این دو گروه خواسته شد تا شناسایی کنند که کدام یک از «بیماران» انسان هستند و کدام یک برنامه های کامپیوتری. [۳۲] روانپزشکان توانستند شناسایی صحیح را تنها در ۴۸ درصد از موارد - رقمی سازگار با حدس تصادفی- انجام دهند. [33] در قرن بیست و یکم، نسخه هایی از این برنامه ها (که اکنون با نام"chatterbots"شناخته می شود) همچنان مردم را گولمی زنند. CyberLove  که یک برنامه بدافزار است، با متقاعد کردن مردم به «آشکار کردن اطلاعات مربوط به هویت شان یا هدایت آن ها به بازدید از یک وب سایت که محتوای مخرب را به رایانه هایشان تحویل خواهد داد» کاربران را طعمه خود می¬کرد. [34] این برنامه به عنوان "خطرِ ولنتاین" با سر به سر گذاشتن با مردم در جهت برقراری روابط آنلاین، به منظور جمع آوری اطلاعات شخصی آن ها ظهور کرد. [35]
مقاله ذهن ، مغز ، و برنامه¬ها ی جان سرل در سال 1980 آزمایش "اتاق چینی" را پیشنهاد کرد و استدلال کرد که آزمون تورینگ نمی تواند مورد استفاده قرار گیرد برای تعیین اینکه آیا یک ماشین می تواند فکر کند یا نه. سرل اشاره کرد که نرم افزارها (مانند ELIZA) می توانند آزمون تورینگ را به سادگی با دستکاری نمادهایی که هیچ درک درستی از آن ها ندارند، بگذرانند. بدون درک ، نمی توان آن ها را «متفکر» به همان معنا انسان ها هستند توصیف کرد. بنابراین سرل نتیجه می گیرد، آزمایش تورینگ نمی تواند ثابت کند که یک ماشین می تواند فکر کند. [36] بسیار شبیه به خود آزمون تورینگ، استدلالی که سرل ارائه داد هم به طور گسترده ای مورد انتقاد قرار گرفت  [37] و هم بسیار تایید شده است. [38] استدلال هایی مانند سرل و دیگرانی که بر روی فلسفه ذهن کار می کردند، جرقه ای برای بحث شدیدتر در مورد ماهیت هوش، امکان ماشین های هوشمند و ارزش آزمون تورینگ را روشن کرد که تا سال های ۱۹۸۰ و ۱۹۹۰ ادامه یافت. [39]
جایزه لوبنر یک بستر سالانه برای آزمایش های عملی تورینگ فراهم می کند که اولین مسابقه ی آن در نوامبر ۱۹۹۱ برگزار شد. [۴۰]  توسط هیو لوبنر نوشته شده است. مرکز مطالعات رفتاری کمبریج  در ماساچوست ایالات متحده آمریکا جوایز این مسابقه را تا سال ۲۰۰۳ سازماندهی کرد. همان طور که لوبنر آن را توصیف کرد، یکی از دلایل ایجاد این رقابت پیشبرد وضعیت تحقیقات هوش مصنوعی، حداقل تا حدودی است، زیرا با وجود ۴۰ سال بحث در مورد آن، کسی برای اجرای آزمون تورینگ گام برداشته نبود. [41] اولین مسابقه جایزه لوبنر در سال ۱۹۹۱ منجر به بحث مجدد و زنده ماندن آزمون تورینگ و تبئین ارزش پیگیری آن، هم در مطبوعات محبوب[۴۲] و هم در آکادمی شد. [43] در اولین مسابقه توسط یک برنامه بدون-فکر و بدون هوشِ قابل شناسایی که موفق به گول زدن بازجویان ساده لوح به شناساییِ اشتباه، برنده شد.   این موضوع چند کاستی از آزمون تورینگ را برجسته کرد(مورد بحث در زیر ):برنامه ی ساده ی ارائه شده برنده شد، زیرا حداقل در بخشی از آن، قادر به "تقلید از خطاهای تایپانسان"بود ؛ [42]  بازجویان ساده لوح به راحتی گول میخورند. [43] و برخی محققان هوش مصنوعی احساس میکردند که این آزمون صرفا یک حواس پرتی از تحقیقات پربارتر است. [44] جوایز نقره (فقط متن) و طلا (صوتی و بصری) هرگز به کسی داده نشد. با این حال، این رقابت هر سال مدال برنز را برای سیستم کامپیوتری¬ای اعطا کرده است که به نظر قضات، «انسانی ترین» رفتار مکالمه ای را در میان مدخل های آن سال نشان می دهد.  نهاد رایانه ای اینترنت زبانی مصنوعی  (A.L.I.C.E) در سه نوبت در سال های(۲۰۰۰، ۲۰۰۱، ۲۰۰۴) برنده جایزه برنز شده است. جایزه لوبنر هوش مکالمه ای را آزمایش می کند؛ برندگان به طور معمول برنامه های  chatterbot،  و یا نهادهای مکالمه نهادهای مکالمه مصنوعی (ACE)  هستند. قوانین اولیه جایزه لوبنر مکالمات را محدود می کرد: هر ورودی مسابقه و انسان های پنهان(انسان پنهان) بر روی یک موضوع واحد متمرکز می شدند،[۴۵] به این ترتیب بازجویان به یک خط پرسش در هر تعامل محدود می شدند. قانون مکالمه محدود برای جایزه لوبنر در سال ۱۹۹۵ برداشته شد. مدت تعامل بین قاضی و نهاد در جوایز لوبنر متفاوت بوده است. در لوبنر ۲۰۰۳، در دانشگاه سوری، به هر بازجو پنج دقیقه اجازه داده شد تا با یک نهاد، ماشین یا انسان پنهان تعامل داشته باشد. بین سال های ۲۰۰۴ تا ۲۰۰۷ زمان تعامل مجاز در جوایز لوبنر بیش از بیست دقیقه بود.
ساول ترایگر استدلال می کند که حداقل سه نسخه اولیه از آزمون تورینگ وجود دارد که دو نسخه از آن ها در "ماشین آلات محاسباتی و هوش" و نسخه ای که او آن را «تفسیر استاندارد» توصیف می کند، ارائه می شود. [46] در حالی که برخی بحث ها در مورد اینکه آیا "تفسیر استاندارد"آن است که توسط تورینگ توصیف شده است و یا، در عوض، بر اساس خواندن غلط مقاله، این سه نسخه به عنوان معادل در نظر گرفته نمی شود،[46] و نقاط قوت و ضعف خود را دارند. [47] هوما شاه اشاره می کند که خود تورینگ نگران این بود که آیا یک ماشین می تواند فکر کند یا نه و روش ساده ای برای بررسی این موضوع ارائه می داد: از طریق جلسات پرسش و پاسخ انسان-ماشین. [۴۸] شاه استدلال می کند که یک بازی تقلیدی وجود دارد که همنطور که تورینگ توصیف کرد می تواند به دو روش مختلف عملی شود: الف) آزمون بازپرس-ماشین یک به یک، و ب) مقایسه همزمان یک ماشین با یک انسان، هر دو به موازات یک بازپرس مورد پرسش قرار می گیرد. [25] از آنجا که آزمون تورینگ آزمونی از تشخیص ناپذیری در ظرفیت عملکرد است، نسخه کلامی به طور طبیعی به تمام ظرفیت عملکرد انسان، کلامی و همچنین غیرکلامی (رباتیک) عمومیت می بخشد. [49]
مقاله اصلی تورینگ یک بازی مهمانی ساده را توصیف می کند که شامل سه بازیکن می شود. بازیکن الف مرد است، بازیکن ب یک زن است و بازیکن ج (که نقش بازجو را بازی می کند) از هر دو جنس است. در بازی تقلید، بازیکن ج قادر به دیدن بازیکن الف یا بازیکن ب نیست، و تنها از طریق یادداشت های کتبی می تواند با آن ها ارتباط برقرار کند. بازیکن ج با پرسیدن سوالات از بازیکن الف و بازیکن ب سعی می کند مشخص کند که کدام یک از این دو مرد است و کدام زن است. نقش بازیکن الف این است که فریب بازجو را به تصمیم گیری اشتباه، در حالی که بازیکن ب تلاش برای کمک به بازجو در ساخت یکی از حق است. [7] تورینگ سپس می پرسد: چه اتفاقی خواهد افتاد زمانی که یک ماشین نقش الف را در این بازی ایفا کند؟ آیا بازجو همانطور به اشتباه تصمیم خواهد گرفت مانند هنگامی که در نسخه ی اصلی بازی اشتباه تصمیم میگرفت؟ این سوالات جایگزین اصلی ما می شوند، "آیا ماشین ها می توانند فکر کنند؟" [24]
نسخه دوم بعدها در مقاله تورینگ در سال ۱۹۵۰ ظاهر شد. مشابه تست بازی تقلید اصلی، نقش بازیکن الف توسط یک کامپیوتر انجام می شود. با این حال، نقش بازیکن ب توسط یک مرد انجام می شود تا یک زن. اجازه دهید توجه مان را بر روی یک کامپیوتر دیجیتال خاص ج معطوف کنیم.  آیا درست است که با اصلاح این کامپیوتر به منابع ذخیره سازی کافی، افزایش سرعت پردازش، و ارائه آن را با یک برنامه مناسب، ج می تواند طوری ساخته شود که به ایفای نفش رضایت بخشی از الف در بازی تقلید دست یابد؟ (در حالی که انسان در نقش ب در حال ایفای نقش باشد)؟ [24] در این نسخه هم بازیکن الف (کامپیوتر) و هم بازیکن ب در تلاش هستند تا بازجو را فریب دهد تا تصمیم نادرستی بگیرد.
درک مشترک آن است که هدف از آزمون تورینگ به طور خاص برای تعیین اینکه آیا یک کامپیوتر قادر به گول زدن یک بازجو به این باور هست که آن یک انسان است، بلکه اینکه آیا یک کامپیوتر می تواند رفتار یک انسان را تقلید کند. [7] در حالی که برخی از اختلاف وجود دارد که آیا این تفسیر توسط تورینگ در نظر گرفته شده است، استرت معتقد است که آن تفسیر تورینگ هست  [50] و در نتیجه نسخه دوم را با این یکی می¬داند، در حالی که دیگران، مانند تریگر، این گونه نمی اندیشند[46] - با این حال منجر به آنچه که می توان از آن به عنوان "تفسیر استاندارد" یاد می شود، شد. در این نسخه، بازیکن الف یک کامپیوتر و بازیکن ب یک فرد از هر دو جنس است. نقش بازجو تعیین این نیست که کدام مرد است و کدام زن است، بلکه کدام کامپیوتر است و کدام یک انسان است. [51] مسئله اساسی با تفسیر استاندارد این است که بازجو نمی تواند تشخیص دهد که کدام پاسخ دهنده انسان است، و کدام ماشین است. مسائلی در مورد مدت زمان بازجویی وجود دارد، اما تفسیر استاندارد به طور کلی این محدودیت را چیزی می بیند که باید معقول باشد.
جنجال بر سر اینکه کدام یک از فرمول بندی های جایگزین آزمون را تورینگ در نظر گرفته بود به وجود آمده است. [50] استرت استدلال می کند که دو آزمایش متمایز را می توان از مقاله خود را در سال 1950  استخراج کرد که،بر اساس لحن سخنان تورینگ، آنها معادل نیست. آزمونی که بازی مهمانی را به کار می گیرد و فرکانس های موفقیت را مقایسه می کند، به «آزمون بازی تقلید اصلی» گفته می شود، در حالی که آزمون متشکل از یک قاضی انسانی در مقابل یک انسان و یک ماشین به عنوان «آزمون تورینگ استاندارد» گفته می شود، با توجه به اینکه استرت این موضوع را با «تفسیر استاندارد» برابر می¬داند تا نسخه دوم بازی تقلید. استرت موافق است که آزمون استاندارد تورینگ (STT) مشکلاتی را دارد که منتقدان آن به آن استناد می کنند اما احساس می کنند که در مقابل، آزمون بازی تقلید اصلی (آزمون OIG) طوری تعریف شده که در برابر بسیاری از آن ها مصون است، به دلیل یک تفاوت بسیار مهم: بر خلاف STT، آن شباهتی به عملکرد انسان معیار ایجاد نمی کند، حتی اگر عملکرد انسان را در تعیین معیار هوش ماشینی به کار می گیرد. یک انسان می تواند در آزمون OIG را شکست بخورد، اما استدلال می شود که ذات آزمون هوش این است که شکست نشان دهنده عدم مدبر بودن است: آزمون OIG نیاز به مدبرانه بودن مرتبط با هوش دارد و نه صرفاً «شبیه سازی رفتار مکالمه ای انسان». ساختار کلی آزمون OIG حتی می توانست با نسخه های غیر کلامی بازی های تقلیدی مورد استفاده قرار گیرد. [52] هنوز هم نویسندگان دیگر[53] پیشنهاد تورینگ را به این تفسیر کرده اند که بازی تقلید خود آزمون است، بدون مشخص کردن چگونگی در نظر گرفتن بیانیه تورینگ، که آزمونی که او با استفاده از نسخه بازی مهمانی تقلید پیشنهاد کرد بر اساس معیار فراوانی نسبی موفقیت در آن بازی تقلیدی است، به جای ظرفیتی برای موفقیت در یک دور از بازی. سیگین پیشنهاد کرده است که شاید بازی اصلی راهی برای پیشنهاد یک طراحی تجربی کمتر مغرضانه باشد چرا که مشارکت کامپیوتر را پنهان می کند. [54] بازی تقلید نیز شامل "هک اجتماعی" است که در تفسیر استاندارد یافت نمی شود، به این عنوان که در بازی هر دو کامپیوتر و انسان مذکر تظاهر به بودن کسی کنند که در حقیقت نیستند. [55]
یک قطعه بسیار مهم از هر آزمایش آزمایشگاهی این است که باید یک کنترل وجود داشته باشد. تورینگ هرگز روشن نمی کند که آیا بازجو در آزمایش هایش آگاه است که یکی از شرکت کنندگان یک کامپیوتر است یا نه. با این حال، اگر ماشینی وجود داشت که ظرفیت گذراندن یک آزمایش تورینگ را داشت، بی خطر خواهد بود که فرض کنیم کنترل کور مضاعف لازم خواهد بود. برای بازگشت به بازی تقلید اصلی، او تنها بیان می کند که بازیکن الف قرار است با یک ماشین جایگزین شود، نه اینکه آن بازیکن ج از این جایگزینی آگاه شود. [24] هنگامی که کولبی، اف.دی هیلف، اس وبر و ای.دی کرامر PARRY را آزمایش کردند، این کار را با فرض اینکه بازجوها نیازی به دانستن این که یک یا چند نفر از کسانی که با آنها مصاحبه می شود، یک کامپیوتر است، انجام دادند. [56] همانطور که آیس سایگین، پیتر سوییرسکی ،[57] و دیگران خاطر نشان کردند، این باعث به وجود آمدن تفاوت زیادی می شود؛ چه در پیاده سازی و چه در نتیجه آزمون. [7] یک مطالعه تجربی با نگاهی به تخلفات ماکسیم گریسان با استفاده از رونوشت های جایزه یک به یک لوبنر (هم سخن بازجو-پنهان) برای مسابقات هوش مصنوعی بین سال های ۱۹۹۴ تا ۱۹۹۹، آیس سیگین تفاوت های قابل توجهی بین پاسخ شرکت کنندگانی که می دانستند و پاسخ شرکت کنندگانی که نمی دانستند، کامپیوتر ها در آزمون دخیل هستند. [58]
قدرت و جذابیت آزمون تورینگ از سادگی آن حاصل می شود. فلسفه ذهن، روانشناسی ،علوم اعصاب مدرن نتوانسته اند تعاریفی از «هوش» و «تفکر» ارائه دهند که به اندازه کافی دقیق و کلی باشند تا در مورد ماشین ها به کار گرفته شوند. بدون چنین تعاریف نمی توان به پرسش های محوری فسلفه هوش مصنوعی پاسخ داد. آزمایش تورینگ، حتی اگر ناقص باشد، حداقل چیزی را فراهم می کند که در واقع می تواند اندازه گیری شود. به این ترتیب تلاشی عمل گرایانه برای پاسخ به یک پرسش دشوار فلسفی است.
قالب آزمون به بازجو اجازه می دهد تا کارهای فکری بسیار متنوعی به ماشین بدهد. تورینگ نوشت که «به نظر می رسد روش پرسش و پاسخ برای معرفی تقریباً هر یک از زمینه هایی که انسان در آن تلاش کرده و می خواهیم شامل آن شود، مناسب باشد.» [۵۹]   جان هاگلند   می افزاید که «درک کلمات کافی نیست؛ شما هم باید موضوع را نیز درک  کنید.» [60] برای گذراندن یک تست تورینگ که به خوبی طراحی شده، ماشین باید از زبان طبیعی ،  استدلال ، دانش استفاده کند و یاد بگیرد.  این آزمون را می توان گسترش داد تا شامل ورودی ویدئو، و همچنین یک "دریچه" که از طریق آن اشیاء را می توان عبور داد: این کار ماشین را مجبور میکند تا قدرت دید و رباتیک را به خوبی به کار بگیرد. با هم، این ها تقریباً تمام مشکلات عمده ای را نشان می دهند که تحقیقات هوش مصنوعی می خواهند آن ها را حل کنند. [61] آزمون فیگنباوم  برای بهره گیری از طیف گسترده ای از موضوعات موجود در یک آزمون تورینگ طراحی شده است. این یک شکل محدود از بازی پرسش و پاسخ تورینگ است که ماشین را در برابر توانایی های کارشناسان در زمینه های خاص مانند ادبیات یا شیمی مقایسه می کند.  ماشین واتسون  ای بی ام در یک آزمون مرد در مقابل ماشین که در برنامه ای تلویزیونی نشان داده شد به موفقیت دست پیدا کرد[62]
به عنوان فارغ التحصیل افتخارات کمبریج در ریاضیات، ممکن است از تورینگ انتظار رود که یک آزمون از هوش کامپیوتر ارائه دهد که نیاز به دانش متخصصان در برخی از زمینه های بسیار فنی، داشته باشد. در عوض ، همانطور که در اشاره شد ، آزمونی که او در مقاله سمینال خود در سال 1950 توصیف کرد نیاز به آن دارد که کامپیوتر با موفقیت قادر به رقابت در یک بازی رایج مهمانی باشد، و این با وانمود کردن عملکرد مردی/زنی معمولی در پاسخ به یک سری از سوالات ممکن است. با توجه به وضعیت دیمورفیسم جنسی انسان به عنوان یکی از باستانی ترین موضوعات ، در نتیجه ضمنی در سناریوی زیر میتوان یافت که سوالاتی که باید پاسخ داده شوند نباید مستلزم دانش تخصصی و نه تکنیک پردازش اطلاعات باشند. چالش برای کامپیوتر این خواهد بود برای نشان دادن همدلی برای نقش زن، و برای نشان دادن و همچنین حساسیت زیبایی شناختی مشخصه-که هر دو ویژگی در نمایش در این تکیه از گفتگو که تورینگ تصور کرده است: بازجو: ممکن است شرکت کننده لطفا طول موهایش را به من بگوید؟ شرکت کننده: موهایم در هم می ریزد، و طولانی ترین رشته ها حدود نه اینچ طول دارند. هنگامی که تورینگ برخی دانش های تخصصی را به یکی از دیالوگ های تصور شده اش معرفی می کند، موضوع ریاضی یا الکترونیک نیست، بلکه شعر است: بازجو: در خط اول سونیت تو که می خواند: «آیا تو را با یک روز تابستان مقایسه کنم» بهتر نبود از «یک روز بهاری» استفاده می شد؟ شاهد: قافیه¬اش جور در نمیاد. بازجو: «روز زمستان» چگونه است. خيلي خوب قافیه¬اش جور میشه. شاهد: بله، اما هیچکس نمی خواهد با یک روز زمستان مقایسه شود. تورینگ به این ترتیب یک بار دیگر علاقه خود را به همدلی و حساسیت زیبایی شناختی به عنوان اجزای یک هوش مصنوعی نشان می دهد؛ و با توجه به آگاهی فزاینده ای که از تهدید رستاخیز هوش مصنوعی،[63]  پیشنهاد شده است[64] که این تمرکز شاید نشان دهنده شهود انتقادی در سمت تورینگ باشد، به عنوان مثال ، که هوش عاطفی و زیبایی شناختی در ایجاد "هوش مصنوعی دوستانه" نقش کلیدی خواهد داشت. 
تورینگ به صراحت بیان نکرد که آزمون تورینگ می تواند به عنوان اندازه گیری هوش، یا هر کیفیت انسانی دیگری مورد استفاده قرار گیرد. او می خواست جایگزین روشن و قابل فهمی برای کلمه «فکر کردن» ارائه دهد که پس از آن می توانست از آن برای پاسخ به انتقادها از احتمال «ماشین های تفکر» استفاده کند و راه هایی را پیشنهاد کند که تحقیقات ممکن است در آن ها به جلو بروند. با این وجود، آزمون تورینگ به عنوان اندازه گیری «توانایی فکر کردن» یک ماشین یا «هوش» آن پیشنهاد شده است. این پیشنهاد هم از سوی فیلسوفان و هم از سوی دانشمندان کامپیوتر انتقاداتی دریافت کرده است. فرض بر این است که یک بازجو می تواند تعیین کند که آیا یک ماشین با مقایسه رفتارش با رفتار انسان «تفکر» می کند یا نه. هر عنصری از این فرض مورد پرسش قرار گرفته است: قابلیت اطمینان بودن قضاوت بازپرس، ارزش مقایسه تنها رفتار و ارزش مقایسه ماشین با یک انسان. به دلیل این ملاحظات و ملاحظات دیگر، برخی از محققان هوش مصنوعی ارتباط آزمون با حوزه خود را زیر سؤال بردند.
آزمون تورینگ به طور مستقیم آزمایش نمی کند که آیا کامپیوتر هوشمندانه رفتار می کند یا نه. فقط آزمایش می کند که آیا کامپیوتر مثل یک انسان رفتار می کند یا نه. از آنجا که رفتار انسان و رفتار هوشمندانه دقیقاً یکسان نیست، آزمایش می تواند در اندازه گیری دقیق هوش به دو روش شکست بخورد: برخی از رفتار انسان ها هوشمندانه نیست  آزمایش تورینگ ایجاب می کند که ماشین بتواند تمام رفتارهای انسان را بدون در نظر گرفتن اینکه باهوش باشند، اجرا کند. حتی برای رفتارهایی آزمایش می کند که ممکن است به هیچ عنوان هوشمندانه تلقی نشند، مانند حساسیت به توهین ها،[۶۵]  وسوسه دروغ گفتن یا به سادگی فرکانس بالای تایپ اشتباهات. اگر یک ماشین نتواند از این رفتارهای غیر هوشمندانه را به طور مفصل تقلید کند، در آزمایش شکست می¬خورد. این مورد توسط نشریه The Economist ، در مقاله ای با عنوان «حماقت مصنوعی» که اندکی پس از اولین مسابقه جایزه لوبنر در سال ۱۹۹۲ منتشر شد،مطرح شد. در این مقاله اشاره شده بود که اولین پیروزی برنده لوبنر، حداقل تا حدودی، به توانایی آن در «تقلید از خطاهای تایپ انسان» بوده است. [۴۲] خود تورینگ پیشنهاد کرده بود که برنامه ها خطاها را به خروجی خود اضافه کنند، تا «بازیکنان» بهتری در بازی باشند. [66] برخی رفتار هوشمندانه غیر انسانی است  آزمون تورینگ رفتارهای بسیار هوشمندانه ای مانند توانایی حل مشکلات دشوار یا به وجود آمدن بینش های اصلی را آزمایش نمی کند. در واقع به طور خاص نیاز به فریب از طرف ماشین دارد: اگر ماشین باهوش تر از یک انسان باشد باید عمداً از ظاهر شدن بیش از حد باهوش اجتناب کند. اگر قرار بود یک مشکل محاسباتی را حل کند که عملاً حل آن برای یک انسان غیرممکن است، آنوقت بازجو می دانست که برنامه انسان نیست و ماشین در آزمایش شکست می خورد. از آنجا که نمی تواند هوشی را که فراتر از توانایی انسان است اندازه گیری کند، نمی توان از آزمون تورینگ برای ساخت یا ارزیابی سیستم هایی که باهوش تر از انسان هستند استفاده کرد. به این دلیل آزمون های جایگزین متعددی که قادر به ارزیابی سیستم های فوق هوشمند خواهند بود، پیشنهاد شده اند. [67]
مقاله اصلی: اتاق چینی همچنین نگاه کنید به: هوش مصنوعی آزمون تورینگ به شدت نگران نحوه عملکرد مورد مطالعه است (رفتار خارجی ماشین). در این راستا رویکردی رفتار  گرایانه  یا عملکردی نسبت به مطالعه ذهن در پیش می گیرد. مثال ELIZA نشان می دهد که یک ماشین در حال گذراندن آزمون ممکن است بتواند رفتار مکالمه ای انسان را با پیروی از یک لیست ساده (اما بزرگ) از قوانین مکانیکی، بدون فکر کردن یا داشتن ذهن در همه شبیه سازی کند. جان سرل استدلال کرده است که نمی توان از رفتار خارجی برای تعیین اینکه آیا یک ماشین «در واقع» متفکر است یا صرفاً «شبیه سازی تفکر دارد» استفاده کرد. [36]   استدلال اتاق چینی او در نظر گرفته شده است تا نشان دهد که، حتی اگر آزمون تورینگ تعریف عملیاتی خوبی از هوش ارائه داده باشد، ممکن است قادر به نشان دادن اینکه ماشین دارای ذهن، آگاهی، یا تعمد است نباشد. (تعمد اصطلاحی فلسفی است برای اینکه قدرت افکار «درباره» چیزی باشد.) تورینگ این خط انتقاد را در مقاله اصلی خود پیش بینی کرد  [۶۸]&#160;: من نمی خواهم این تصویر که ،هیچ رمز و رازی در مورد آگاهی وجود ندارد، را ارائه دهم. به عنوان مثال، چیزی از یک پارادوکس متصل به هر گونه تلاش برای درک کردن آن وجود دارد. اما من فکر نمی کنم این اسرار لزوما ً باید حل شوند قبل از اینکه بتوانیم به این سوال که در این مقاله مورد توجه ما است، پاسخ دهیم. [69]
در عمل، نتایج آزمون به راحتی می تواند نه توسط هوش کامپیوتر، بلکه با نگرش ها، مهارت ها، یا ساده لوحی پرسش گر تحت سلطه قرار گیرد. تورینگ مهارت ها و دانش دقیق مورد نیاز بازپرس را در توصیف خود از آزمون مشخص نمی کند، اما او از اصطلاح «بازپرس متوسط» استفاده کرد: «[بازپرس متوسط] پس از پنج دقیقه بازجویی بیش از ۷۰ درصد شانس ساخت شناسایی درست را نخواهد داشت». [70] برنامه های chatterbot مانند ELIZA بارها افراد غیر مشکوک را گول داده اند تا باور کنند که با انسان ها ارتباط برقرار می کنند. در این موارد «بازجوها» حتی از احتمال تعامل با رایانه ها نیز آگاه نیستند. برای تقلید موفقیت آمیز انسان، نیازی نیست که ماشین به هر حال هوشی داشته باشد و تنها شباهت سطحی به رفتار انسان مورد نیاز است. مسابقات اولیه جایزه لوبنر از بازجویان «ناپیچیده» استفاده می کرد که به راحتی توسط ماشین ها گول می-خوردند. سازمان دهندگان جایزه لوبنر از سال ۲۰۰۴ فیلسوفان، دانشمندان کامپیوتر و روزنامه نگاران را در میان بازجویان مستقر کردند. با این وجود برخی از این کارشناسان توسط ماشین ها فریب داده شده اند. [71] مایکل شرمر اشاره می کند که انسان ها همواره انتخاب می کنند که اشیاء غیر انسانی را هر زمان که اجازه فرصت داده می شود، انسان در نظر بگیرند، اشتباهی به نام  مغلطه ی انترومورفیک: با اتومبیل های خود صحبت می کنند، میل و نیت خود را به نیروهای طبیعی نسبت می دهند ، و خورشید را به عنوان یک انسان¬مانندِ هوشمند پرستش میکنند. شرمر استدلال می کند اگر آزمون تورینگ در مورد اشیاء مذهبی اعمال شود، پس مجسمه ها، سنگ ها و مکان های بی جان به طور مداوم در طول تاریخ از آزمون عبور کرده اند. این گرایش انسانی به آنتروپوتورفیسم به طور موثر انتظار را در آزمون تورینگ را پایین می آورد، مگر اینکه بازجوها به طور خاص برای جلوگیری از آن آموزش دیده باشند.
یکی از ویژگی های جالب آزمون تورینگ فراوانی اثر کنفدراسیون است - زمانی که انسان های کنفدراسیون (آزمایش شده) توسط بازجوها به اشتباه به عنوان ماشین شناخته میشوند. پیشنهاد شده است که آنچه بازجوها به عنوان پاسخ های انسانی انتظار دارند لزوماً انسان مثالی نیست. در نتیجه می توان برخی افراد را به صورت ماشین دسته بندی کرد. بنابراین این می تواند به نفع یک ماشین رقیب کار کند. به انسان ها دستور داده می شود که «خودشان باشند»، اما گاهی پاسخ های آن ها بیشتر شبیه آن چیزی است که بازجو انتظار دارد از ماشینی بشنود. [۷۲]  این موضوع این پرسش را مطرح می کند که چگونه می شود اطمینان حاصل کرد که انسان ها انگیزه ای برای «عمکرد انسانی» دارند.
یک جنبه بحرانی از آزمون تورینگ این است که یک ماشین نباید با گفته های خود هویت ماشینی خود را فاش کند. بازجو پس از آن باید "شناسایی درست" را با شناسایی طرف صحبت به عنوان ماشین داشته باشد. اگر با این حال یک ماشین در طول یک مکالمه سکوت می کند، آنگاه بازجو نمی تواند ماشین را به غیر از یک حدس محاسبه شده به دقت شناسایی کند. [73] حتی در نظر گرفتن یک انسان موازی/ پنهان به عنوان بخشی از آزمون کمکی به وضعیت نمی کند چون¬که انسان اغلب می تواند به عنوان یک ماشین اشتباه گرفته شود. [74]
محققان محوری هوش مصنوعی استدلال می کنند که تلاش برای گذارندن آزمون تورینگ صرفاً حواس پرتی از تحقیقات پربارتر است. [44] در واقع، آزمون تورینگ مورد تمرکز تلاش های دانشگاهی یا تجاری زیادی نیست—همان طور که استوارت راسل و پیتر نورویگ می نویسند: «محققان هوش مصنوعی توجه چندانی به گذراندن آزمون تورینگ اختصاص نداده اند.» [۷۵]  دلایل متعددی وجود دارد. اولا که راه های ساده تری برای آزمایش برنامه های آن ها وجود دارد. بیشتر تحقیقات فعلی در زمینه های مرتبط با هوش مصنوعی  با هدف اهداف خاص مانند زمان بندی خودکار، تشخیص شیء ، یا پشتیبانی است. محققان هوش مصنوعی برای آزمایش هوش برنامه هایی که این مشکلات را حل می کنند، به سادگی این وظیفه را به طور مستقیم به آنها می دهند. راسل و نورویگ  قیاسی با سابقه پرواز پیشنهاد می کنند: "هواپیماها با اینکه چقدر خوب پرواز می کنند آزمایش می شوند، نه با مقایسه آن هابا پرندگان". متون مهندسی هواپیما، آنها می نویسند، "هدف از فعالیت های حوزه خود را تحت عنوان ساخت  ماشین آلاتی که پرواز آن ها دقیقا مانند کبوتر است به طوری که می توانند کبوتر های دیگر گول بزنند، تعریف نمی کند. "[75] دوم اینکه ایجاد شبیه سازهای زندگی های مانند انسان به خودی خود یک مشکل دشوار است که برای رسیدن به اهداف اساسی تحقیقات هوش مصنوعی نیازی به حل آن ها نیست. شخصیت های انسانی باورپذیر ممکن است در یک اثر هنری، یک بازی ، یا یک رابط کاربری پیچیده جالب توجه باشند ، اما آنها بخشی از علم ایجاد ماشین های هوشمند نیستند، که عبارت است از ماشین هایی که مشکلات را با استفاده از هوش حل میکنند. تورینگ می خواست مثال روشن و قابل درک برای کمک در بحث فلسفه هوش مصنوعی ارائه دهد. [۷۶] جان مک کارتی بیان می کند که فلسفه هوش مصنوعی «بعید است که تأثیر بیشتری برتحقیقات هوش مصنوعی در عمل نسبت به فلسفه علم که به طور کلی بر روی علم تاثیر دارد، داشته باشد.» [77]
رابرت فرنچ (۱۹۹۰)  این مورد را مطرح می کند که یک بازپرس می تواند با طرح پرسش هایی که فرایندهای سطح پایین (به عنوان ناخودآگاه) شناخت انسان را آشکار می کند، همان طور که توسط علم شناختی مورد مطالعه قرار می گیرد، هم¬صحبتی های انسانی و غیر انسانی را متمایزکند. چنین پرسش هایی جزئیات دقیق تجسم انسان از فکر را آشکار می کند و می تواند یک کامپیوتر را تشخیص دهد مگر اینکه جهان را آنطور که انسان ها تجربه می کنند تجربه کند. [78]
مقالات اصلی: آزمون تورینگ معکوس  و  CAPTCHA اصلاح آزمون تورینگ که در آن هدف یک یا چند نقش بین ماشین ها معکوس شده اند و انسان یک آزمایش تورینگ معکوس گفته می شود. مثالی ضمنی در کار روانکاو ویلفرد Wilfred Bionبیون[۷۹] است که به ویژه مجذوب «طوفان» شده بود که ناشی از برخورد یک ذهن توسط ذهن دیگر, بود. پیتر سویرسکی، دانشمند ادبی در کتاب سال ۲۰۰۰ خود،[۵۷]   Peter Swirski در میان چندین نقطه اصلی دیگر با توجه به آزمون تورینگ، به طور مفصل در مورد این ایده که او آزمون سویرسکی را اساساً آزمون تورینگ معکوس می نامد، بحث کرد. او اشاره کرد که بیشتر غلبه می کند اگر نه تمام اعتراض های استاندارد تسطیح شده در نسخه استاندارد. با حمل این ایده به جلو، R. D. Hinshelwood[80] ذهن را به عنوان یک "ذهن به رسمیت شناختن دستگاه" توصیف کرد. چالش این خواهد بود که کامپیوتر بتواند تعیین کند که آیا با یک انسان یا یک کامپیوتر دیگر تعامل دارد یا نه. این گسترش سوال اصلی است که تورینگ تلاش برای پاسخ به اما، شاید، ارائه یک استاندارد به اندازه کافی بالا برای تعریف یک ماشین است که می تواند "فکر می کنم" در راه است که ما به طور معمول به عنوان مشخصه انسان تعریف است. CAPTCHA شکلی از آزمون تورینگ معکوس است. قبل از اینکه اجازه داده شود برخی از عمل ها را در یک وب سایت انجام دهد، به کاربر کاراکتر های عددی-الفبایی در یک تصویر گرافیکی به هم ریخته شده ارائه می شود و از او خواسته می شود که آن ها را تایپ کند. این امر برای جلوگیری از استفاده سیستم های خودکار برای سوء استفاده از سایت در نظر گرفته شده است. منطق این است که نرم افزاری به اندازه کافی پیچیده برای خواندن تصویر به ریخته شده، با دقت بالا، وجود ندارد (یا در دسترس کاربر متوسط نیست)، بنابراین هر سیستمی که بتواند این کار را انجام دهد به احتمال زیاد یک انسان است. بعد از معرفی CAPTCHA نرم افزار هایی که بتوانند CAPTCHA را با دقت مناسبی، بوسیله ی تجزیه و تحلیل الگوهای موجود در موتور تولید CAPTCHA باز خوانی کنند، به سرعت شروع به توسعه یافتند. [۸۱] در سال ۲۰۱۳ محققان شرکت  Vicarious اعلام کردند که سیستمی را برای حل چالش های CAPTCHA که در شرکت هایی چون گوگل ، یاهو ، و پی پال به کار گرفته می شوند را با دقت ۹۰٪ توسعه داده اند. [۸۲] در سال ۲۰۱۴ مهندسان گوگل سیستمی را معرفی کردند که می تواند چالش های CAPTCHA را با دقت ۹۹٫۸٪ شکست دهد. [83] در سال 2015، Shuman Ghosemajumder ، اظهار داشت که سایت های مجرم سایبری ای وجود دارند که چالش های CAPTCHA در قبال دریافت هزینه ای شکست میدهند تا اشکال مختلف تقلب قابل دسترسی باشد. [84]
مقاله اصلی: آزمون تورینگ کارشناس موضوع تنوع دیگری به عنوان آزمون تورینگِ subject-matter expert وجود دارد؛ که در آن پاسخ یک ماشین را نمی توان از یک کارشناس در یک زمینه مشخص متمایز کرد. این موضوع به عنوان «آزمون فیگنباوم» نیز شناخته می شود و توسط ادوارد فیگنباوم در مقاله ای در سال ۲۰۰۳  پیشنهاد شد. [85]
"تست تورینگ کل"[49]   تنوعی از آزمون تورینگ است که توسط دانشمند شناختی استوان هارند پیشنهاد شده است،[86] که دو مورد بیشتر به آزمون تورینگ سنتی می افزاید. بازجو همچنین می تواند توانایی های ادراکی سوژه (نیاز به دید رایانه ای) و توانایی سوژه در دستکاری اشیاء (نیاز به رباتیک) را آزمایش  کند. [87]
نامه ای در ارتباطات ACM[88] منتشر شده است که مفهوم تولید یک جمعیت بیمار مصنوعی را توصیف می کند و تنوعی از آزمایش تورینگ را برای ارزیابی تفاوت بین بیماران مصنوعی و واقعی پیشنهاد می کند. در این نامه آمده است: «در زمینه EHR، هر چند یک پزشک انسانی می تواند به آسانی بین بیماران انسانی مصنوعی تولید شده و واقعی زنده تمایز قائل شود، اما آیا یک ماشین هوش مصنوعی نیز می تواند این کار را انجام دهد؟» و در ادامه این نامه آمده است: «قبل از اینکه هویت بیمار مصنوعی به یک مشکل بهداشت عمومی تبدیل شود، بازار EHR میتواند از تکنیک های مانند آزمون تورینگ برای اطمینان از قابلیت داده ها و ارزش تشخیصی بهره مند شود. به این ترتیب هر تکنیک جدیدی باید هتروژنی بیماران را در نظر بگیرد و به احتمال زیاد پیچیدگی بیشتری نسبت به آزمون علوم کلاس هشتمی آلن داشته باشد که قادر به تشخیص باشد.»
مقاله اصلی: حداقل تست سیگنال هوشمند حداقل تست سیگنال هوشمند توسط کریس مک کینستری به عنوان "حداکثرِ انتزاع آزمون تورینگ" پیشنهاد شد،[89] که در آن تنها پاسخ های دودویی (درست/غلط یا بله/خیر) مجاز هستند، تا تنها بر ظرفیت فکر تمرکز کنند.  این مشکلات چتِ متنی مانند سوگیری آنتروپو مورفیسم را حذف میکند و به تقلید از رفتار غیر هوشمند انسان نیاز ندارد به سیستم ها اجازه ی عبور از هوش انسانی را می دهد. سوالات باید هر کدام بدون تغیر بمانند، با این حال، آن را بیشتر شبیه به یک آزمون ضریب هوشی می کند تا بازجویی. از آن به طور معمول برای جمع آوری داده های آماری استفاده می شود که در برابر آن ها عملکرد برنامه های هوش مصنوعی ممکن است اندازه گیری شود. [90]
سازمان دهندگان جایزه هاتر بر این باورند که فشرده سازی متن زبان طبیعی یک مشکل هوش مصنوعی سخت است که معادل گذراندن آزمون تورینگ است. آزمون فشرده سازی داده ها دارای مزایایی نسبت به اکثر نسخه ها و تنوع آزمون های تورینگ است، از جمله: •	یک عدد واحد می دهد که می تواند به طور مستقیم برای مقایسه کدام یک از دو ماشین «باهوش تر است» استفاده شود. •	نیازی به دروغ گفتن کامپیوتر به قاضی ندارد از معایب اصلی استفاده از فشرده سازی داده ها به عنوان یک آزمون می باشد: •	نمی توان انسان ها را این طور آزمایش کرد. •	معلوم نیست که چه "نمره" خاصی در این آزمون—اگر وجود داشته باشد—معادل گذراندن یک آزمون تورینگ در سطح انسان است.
یک رویکرد مرتبط با جایزه هاتر که در اواخر دهه ۱۹۹۰ بسیار زودتر ظاهر شد، گنجاندن مشکلات فشرده سازی در یک آزمون تورینگ گسترده است. [91]  یا با آزمایش هایی که به طور کامل از پیچیدگی کولموگروف مشتق شده اند. [92] سایر آزمایش های مرتبط در این خط توسط هرناندز-اورالو و دووی ارائه شده است. [93] ضریب هوشی الگوریتمی، یا AIQ ، تلاشی برای تبدیل اندازه گیری هوش جهانی نظری از لگ و هاتر (بر اساس استنباط استقرای سلیمانوف) به یک آزمون عملی کاری هوش ماشینیاست. [94] دو مزیت عمده برخی از این آزمایش ها، قابلیت درخواست آن ها در هوش های غیرانسانی و عدم الزام آن ها به آزمایش کنندگان انسانی است.
آزمون تورینگ الهام بخش آزمون ایبرت بود که در سال ۲۰۱۱ توسط راجر ایبرت، منتقد فیلم ، پیشنهاد شد که آزمونی است که آیا یک صدای تولید شده مبتنی بر کامپیوتر مهارت کافی از نظر آوا، هجوم ها، زمان بندی و مانند آن دارد تا مردم را به خنده بیندازد.  [95]
تورینگ پیش بینی کرد که ماشین ها در نهایت قادر خواهند بود آزمون را بگذرانند؛ در واقع او تخمین زد که تا سال ۲۰۰۰ ماشین هایی با حدود ۱۰۰ مگابایت ذخیره سازی قادر خواهند بود ۳۰٪ قضات انسان را در یک آزمایش پنج دقیقه ای گول بزنند و مردم دیگر عبارت «ماشین تفکر» را متناقض در نظر نخواهند گرفت. [۵] (در عمل، از سال ۲۰۰۹–۲۰۱۲، شرکت کنندگان جایزه لوبنر تنها یکبار موفق به گول زدن یک قاضی شدند،  [۹۶]   و این تنها به دلیل شرکت کننده انسانی¬ای بود که وانمود می کرد چت بات است. [97])  او بیشتر پیش بینی کرد که یادگیری ماشین بخش مهمی از ساخت ماشین های قدرتمند خواهد بود، ادعایی که توسط محققان معاصر در هوش مصنوعی قابل قبول تلقی می شود. [70] دکتر شین تی مولر در مقاله ای که در سال ۲۰۰۸ به نوزدهمین کنفرانس هوش مصنوعی و علوم شناختی غرب میانه ارائه شد، پیش بینی کرد که یک آزمایش تورینگ اصلاح شده به نام «دکاتلون شناختی» می تواند ظرف پنج سال انجام شود. [98] ری کورزویل آینده گرا با برون یابی رشد نمایی فناوری در طول چند دهه پیش بینی کرد که رایانه های با قابلیت آزمایش تورینگ در آینده ای نزدیک ساخته خواهند شد. او در سال ۱۹۹۰ سال را در حدود سال ۲۰۲۰ تعیین کرد. [۹۹] تا سال ۲۰۰۵، او برآورد خود را تا سال ۲۰۲۹ تمدید کرده بود. [100] پروژه شرط بندی طولانی شرط Nr. 1 شرط بندی 20،000  دلار بین میچ کاپور (بدبین) و ری کورزویل (خوش بین) در مورد اینکه آیا یک کامپیوتر موفق خواهد شد که آزمون تورینگ طولانی را تا سال 2029 بگذارند. در طول آزمون طولانی در حال حاضر تورینگ، هر یک از سه قاضی آزمون تورینگ مصاحبه های آنلاین از هر یک از چهار نامزد آزمون تورینگ (یکی، کامپیوتر و سه تورینگ تست فویل انسان) به مدت دو ساعت هر یک به مدت مجموع هشت ساعت مصاحبه انجام دهد. شرط بندی برخی شرایط را در به جزئیات مشخص می کند. [101]
سال ۱۹۹۰ چهارمین سالگرد اولین انتشار مقاله «ماشین آلات و هوش محاسباتی» تورینگ بود و علاقه مجدد به این آزمون را به خود دید. دو رویداد قابل توجه در آن سال رخ داد: اولی کنفرانس تورینگ بود که در ماه آوریل در دانشگاه ساسکس برگزار شد، و دانشگاهیان و محققان را از رشته های بسیار متنوعی گرد هم آورد تا در مورد آزمون تورینگ از نظر گذشته، حال و آینده اش بحث کنند؛ دومی تشکیل مسابقه سالانه جایزه لوبنر بود. بلای ویتبی چهار نقطه عطف عمده در تاریخ آزمون تورینگ را یاد کرد- انتشار "ماشین آلات محاسباتی و هوش" در سال ۱۹۵۰، معرفی ELLIZA توسط جوزف ویزنبام در سال ۱۹۶۶، توسعه¬ی PARRY توسط کنت کولبی  که برای اولین بار در سال ۱۹۷۲ معرفی شد و کنفرانس تورینگ در سال 1990.  [102]
در نوامبر ۲۰۰۵، دانشگاه سورِی میزبان یک جلسه افتتاحیه یک روزه توسعه دهندگان نهاد مکالمه مصنوعی بود،[۱۰۳] که با حضور برندگان آزمون های عملی تورینگ در جایزه لوبنر: رابی گارنر، ریچارد والاس و رولو کارپنتر برگزار شد. سخنرانان دعوت شده شامل دیوید  هامیل، هیو لوبنر(حامی  Loebner Prizeجایزهلوبنر) و هوما شاه بودند.
به موازات جایزه لوبنر که در سال ۲۰۰۸ در دانشگاه ریدینگ برگزار شد، انجمن مطالعه هوش مصنوعی و شبیه سازی رفتار (AISB)،  میزبان یک جلسه یک روزه برای بحث در مورد آزمون تورینگ بود که توسط جان بارندن ، مارک بیشاپ ، هوما شاه و کوین وارویک سازماندهی شدهبود. [105]   سخنرانان شامل بارونس سوزان گرینفیلد مدیر موسسه سلطنتی،Selmer Bringsjord  ، زندگی نامه نویس تورینگ اندرو هاجس ، و دانشمند "آگاهی¬شناسی" اوون هلند. هیچ توافقی برای یک آزمون تورینگ متعارف ظهور نکرد، هر چند Bringsjord بیان کرد که یک جایزه¬ای قابل منجر خواهد شد که آزمون تورینگ زودتر انجام شود.
در طول سال ۲۰۱۲ رویدادهای بزرگ متعددی به منظور بزرگداشت زندگی و تأثیر علمی تورینگ رخ داد. گروه تورینگ۱۰۰ از این رویدادها حمایت کرد و همچنین یک رویداد ویژه آزمون تورینگ را در بلچلی پارک در23  ژوئن ۲۰۱۲ برای جشن صدمین سالگرد تولد تورینگ سازماندهی کرد.
تست تورینگ یک تست از توانایی ماشین است برای نمایش دادن رفتاری هوشمندانه شبیه به انسان. آزمون تورینگ در سال ۱۹۵۰ توسط آلن تورینگ، ریاضیدان انگلیسی مطرح گردید. ایت آزمون توانایی یک ماشین در نشان دادن رفتار هوشمندانه معادل، یا غیرقابل تشخیص از یک انسان است. تورینگ پیشنهاد کرد که یک ارزیاب انسانی در مورد مکالمات زبان طبیعی بین یک انسان و ماشینی که برای تولید پاسخ های شبیه انسان طراحی شده است، قضاوت کند. ارزیاب آگاه خواهد بود که یکی از دو شریک در گفتگو یک ماشین است، و همه شرکت کنندگان از یکدیگر جدا خواهند شد. مکالمه به یک کانال تنها متن مانند صفحه کلید کامپیوتر و صفحه نمایش محدود می شود تا نتیجه به توانایی ماشین در تبدیل گفتار به کلمات  بستگی نداشته باشد. [3]  اگر ارزیاب نتواند به طور قابل اعتمادی به ماشین از انسان بگوید، گفته می شود که ماشین آزمایش را پشت سر کرده است.  نتایج آزمایش به توانایی ماشین در دادن پاسخ های درست به سوالات بستگی ندارد، تنها اینکه پاسخ های آن چقدر نزدیک به پاسخ هایی است که یک انسان میدهد.
