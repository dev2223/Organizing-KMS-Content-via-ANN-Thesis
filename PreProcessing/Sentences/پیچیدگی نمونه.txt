پیچیدگی نمونه یک الگوریتم یادگیری ماشین، برابر است با تعداد نمونه‌های یادگیری که برای موفقیت الگوریتم لازم است. به صورت دقیق‌تر، پیچیدگی نمونه برابر است با حداقل تعداد نمونه‌های لازم، تا تابع خروجی الگوریتم با احتمالی نزدیک به «یک» در فاصله‌ای نزدیک به «صفر» از تابع هدف قرار گیرد. پیچیدگی نمونه به دو صورت در نظر گرفته می‌شود:
طبق قضیه از ناهار مجانی خبری نیست می‌دانیم که در حالت کلی، پیچیدگی نمونه نوع قوی بی‌نهایت است. به عبارت دیگر هیچ الگوریتم یادگیری‌ای وجود ندارد که بتواند با تعداد محدودی نمونه هر تابع هدفی را یاد بگیرد. به‌هرحال اگر خود را به توابع خاصی مانند توابع خطی یا توابع دودویی محدود کنیم؛ پیچیدگی نمونه محدود است و به بعد وی‌سی مربوط می‌شود.
اگر                         X                 {\displaystyle X}     را مجموعه ورودی‌های ممکن و                         Y                 {\displaystyle Y}     را مجموعه خروجی‌های ممکن در نظر بگیریم،                         Z                 {\displaystyle Z}     را به صورت ضرب دکارتی این دو مجموعه                         X         &#x00D7;         Y                 {\displaystyle X\times Y}     تعریف می‌کنیم. برای مثال برای مسئله دسته‌بندی دو‎کلاسه،                         X                 {\displaystyle X}     یک فضای برداری متناهی و                         Y                 {\displaystyle Y}     برابر با مجموعه                         {         0         ,         1         }                 {\displaystyle \{0,1\}}     است.
                                                H                                     {\displaystyle {\mathcal {H}}}     را مجموعه‌ای از توابع                         h                 {\displaystyle h}     که                         h         :         X         &#x2192;         Y                 {\displaystyle h:X\rightarrow Y}     است در نظر می‌گیریم. یک الگوریتم یادگیری                         A                 {\displaystyle A}     عبارت‌است از تابعی از                                    Z                        &#x2217;                                     {\displaystyle Z^{*}}     به                                                 H                                     {\displaystyle {\mathcal {H}}}    . به‌عبارت دیگر یک الگوریتم یادگیری تعداد محدودی از نمونه‌های یادگیری را دریافت می‌کند و یک تابع                         h         :         X         &#x2192;         Y                 {\displaystyle h:X\rightarrow Y}     را به عنوان خروجی برمی‌گرداند. یک تابع هزینه                         L         :         X         &#x00D7;         Y         &#x2192;                    R                        +                                     {\displaystyle L:X\times Y\rightarrow R^{+}}     را در نظر می‌گیریم، برای مثال این تابع می‌تواند تابع هزینه خطای مربعات                         L         (         y         ,                    y           &#x2032;                  )         =         (         y         &#x2212;                    y           &#x2032;                             )                        2                                     {\displaystyle L(y,y')=(y-y')^{2}}     باشد. برای یک توزیع احتمال                         D                 {\displaystyle D}     داده‌شده روی                         X         &#x00D7;         Y                 {\displaystyle X\times Y}     متوسط خطای تابع                         h                 {\displaystyle h}    ، که یکی از اعضای کلاس فرضیه                                                 H                                     {\displaystyle {\mathcal {H}}}     است، به صورت زیر تعریف می‌شود.
                                                E                             (         h         )         :=                                 E                                   D                             [         L         o         s         s         (         h         (         x         )         ,         y         )         ]         =                    &#x222B;                        X             &#x00D7;             Y                             L         o         s         s         (         h         (         x         )         ,         y         )                  d         D         (         x         ,         y         )                 {\displaystyle {\mathcal {E}}(h):=\mathbb {E} _{D}[Loss(h(x),y)]=\int _{X\times Y}Loss(h(x),y)\,dD(x,y)}    
داده‌های آموزشی یک دنباله                         m                 {\displaystyle m}     تایی از زوج مرتب‌های                         (         x         ,         y         )                 {\displaystyle (x,y)}     به صورت                                    S                        m                             =         (         (                    x                        1                             ,                    y                        1                             )         ,         .         .         .         ,         (                    x                        m                             ,                    y                        m                             )         )         &#x223C;                    D                        m                                     {\displaystyle S_{m}=((x_{1},y_{1}),...,(x_{m},y_{m}))\sim D^{m}}     تشکیل می‌دهند، که تمامی آن‌ها به صورت یکسان و مستقل از توزیع                         D                 {\displaystyle D}     نمونه‌برداری شده‌اند. یک الگوریتم یادگیری                         A                 {\displaystyle A}     به هر دنباله از داده‌های آموزشی                                    S                        m                                     {\displaystyle S_{m}}     یکی از اعضای کلاس فرضیه                                                 H                                     {\displaystyle {\mathcal {H}}}     را نسبت می‌دهد. کمینه خطای کلاس فرضیه                                                 H                                     {\displaystyle {\mathcal {H}}}     به صورت زیر تعریف می‌شود.
                                                               E                                                               H                                                &#x2217;                             =                                 inf                            h               &#x2208;                                                   H                                                                                                  E                             (         h         )                 {\displaystyle {\mathcal {E}}_{\mathcal {H}}^{*}={\underset {h\in {\mathcal {H}}}{\inf }}{\mathcal {E}}(h)}    
                                   h                        m                             =         A         (                    S                        m                             )                 {\displaystyle h_{m}=A(S_{m})}     را خروجی الگوریتم به‌ازای داده‎های آموزشی                                    S                        m                                     {\displaystyle S_{m}}     در نظر می‌گیریم(                                   h                        m                                     {\displaystyle h_{m}}     یک متغیر تصادفی است که به متغیر تصادفی                                    S                        m                                     {\displaystyle S_{m}}     که از توزیع                                    D                        m                                     {\displaystyle D^{m}}     نمونه‌برداری شده‌است بستگی دارد). به الگوریتم                         A                 {\displaystyle A}    ،  قاطع گفته می‌شود اگر                                                 E                             (         h         )                 {\displaystyle {\mathcal {E}}(h)}     به صورت احتمالی به                                                                E                                                               H                                                &#x2217;                                     {\displaystyle {\mathcal {E}}_{\mathcal {H}}^{*}}     میل کند. به‌عبارت دیگر به ازای هر                         &#x03F5;         &gt;         0                 {\displaystyle \epsilon &gt;0}     و                         &#x03B4;         &gt;         0                 {\displaystyle \delta &gt;0}     عدد صحیح و مثبتی مانند                         M                 {\displaystyle M}     وجود داشته‌باشد که به‌ازای هر                         m         &#x2265;         M                 {\displaystyle m\geq M}     داشته‌باشیم
                                   Pr                                       D                                m                                                         [                                 E                             (                    h                        m                             )         &#x2212;                                                E                                                               H                                                &#x2217;                             &gt;         &#x03F5;         ]         &lt;         &#x03B4;         .                 {\displaystyle \Pr _{D^{m}}[{\mathcal {E}}(h_{m})-{\mathcal {E}}_{\mathcal {H}}^{*}&gt;\epsilon ]&lt;\delta .}    
به‌ازای هر الگوریتم یادگیری                         A                 {\displaystyle A}     و                         &#x03F5;         ,         &#x03B4;         ,         D                 {\displaystyle \epsilon ,\delta ,D}     داده شده، پیچیدگی نمونه،                                    M                        A                             (         &#x03F5;         ,         &#x03B4;         ,         D         )                 {\displaystyle M_{A}(\epsilon ,\delta ,D)}     را کمترین مقدار                         M                 {\displaystyle M}     تعریف می‌کنیم که رابطه بالا به‌ازای آن درست باشد. اگر الگوریتم                         A                 {\displaystyle A}     قاطع نباشد، آن‌گاه                                    M                        A                             (         &#x03F5;         ,         &#x03B4;         ,         D         )         =         &#x221E;                 {\displaystyle M_{A}(\epsilon ,\delta ,D)=\infty }    ، هم‌چنین اگر الگوریتمی مانند                         A                 {\displaystyle A}     وجود داشته باشد که                                    M                        A                             (         &#x03F5;         ,         &#x03B4;         ,         D         )                 {\displaystyle M_{A}(\epsilon ,\delta ,D)}     عددی محدود باشد، می‌گوییم کلاس فرضیه                                                 H                                     {\displaystyle {\mathcal {H}}}     قابل یادگیری است.
پیچیدگی نمونه نشان‌دهنده میزان قاطعیت یک الگوریتم است، یعنی به ازای میزان دقت داده‌شده                         &#x03F5;                 {\displaystyle \epsilon }     و میزان اطمینان داده‌شده                         &#x03B4;                 {\displaystyle \delta }     الگوریتم به حداقل                         M         (         &#x03F5;         ,         &#x03B4;         ,         D         )                 {\displaystyle M(\epsilon ,\delta ,D)}     نمونه آموزشی نیاز دارد تا بتواند با احتمال حداقل                         1         &#x2212;         &#x03B4;                 {\displaystyle 1-\delta }    ، خروجی‌ای با خطایی کمتر از                         &#x03F5;                 {\displaystyle \epsilon }     تولید کند. در مدل یادگیری احتمالاً تقریباً صحیح پیچیدگی نمونه باید تابعی چند جمله‌ای از                                                 1             &#x03F5;                                     {\displaystyle {\frac {1}{\epsilon }}}     و                                                 1             &#x03B4;                                     {\displaystyle {\frac {1}{\delta }}}     باشد. به عبارت دیگر باید داشته باشیم:
                        M         (         &#x03F5;         ,         &#x03B4;         )         &#x2208;         O         (         P         o         l         y         (                                 1             &#x03B4;                             ,                                 1             &#x03F5;                             )         )         .                 {\displaystyle M(\epsilon ,\delta )\in O(Poly({\frac {1}{\delta }},{\frac {1}{\epsilon }})).}    
اگر                                                 H                                     {\displaystyle {\mathcal {H}}}     یک مجموعه متناهی از فرضیه‌ها باشد و مجموعه آموزشی                                    S                        m                             =         (         (                    x                        1                             ,                    y                        1                             )         ,         .         .         .         ,         (                    x                        m                             ,                    y                        m                             )         )                 {\displaystyle S_{m}=((x_{1},y_{1}),...,(x_{m},y_{m}))}     به صورت یکسان و مستقل از توزیع                         D                 {\displaystyle D}     نمونه برداری شده باشد آنگاه به‌ازای هر                         0         &lt;         &#x03F5;         &lt;                                 1             2                                     {\displaystyle 0&lt;\epsilon &lt;{\frac {1}{2}}}     و                         0         &lt;         &#x03B4;         &lt;                                 1             2                                     {\displaystyle 0&lt;\delta &lt;{\frac {1}{2}}}     اگر الگوریتم                         A                 {\displaystyle A}     یکی از فرضیه‌های سازگار                         h         &#x2208;                                 H                                     {\displaystyle h\in {\mathcal {H}}}     را به عنوان خروجی تولید کند(فرضیه‌ای سازگار است که روی تمام نمونه‌های آموزشی با تابع هدف یکسان باشد) آنگاه
                                   M                        A                             (         &#x03F5;         ,         &#x03B4;         ,         D         )         &#x2264;                                 1             &#x03F5;                             (         ln         &#x2061;                    |                                          H                                        |                  +         ln         &#x2061;                                 1             &#x03B4;                             )         .                 {\displaystyle M_{A}(\epsilon ,\delta ,D)\leq {\frac {1}{\epsilon }}(\ln |{\mathcal {H}}|+\ln {\frac {1}{\delta }}).}    
                        R         (         h         )         =                    Pr                        x             ,             y             &#x223C;             D                             [         y         &#x2260;         h         (         x         )         ]                 {\displaystyle R(h)=\Pr _{x,y\sim D}[y\neq h(x)]}    
                                                               R               &#x005E;                                          (         h         )         =                                 1             m                                        &#x2211;                        i             =             1                                   n                                        I                  (         h         (                    x                        i                             )         &#x2260;                    y                        i                             )                 {\displaystyle {\hat {R}}(h)={\frac {1}{m}}\sum _{i=1}^{n}\mathbb {I} (h(x_{i})\neq y_{i})}    
می‌دانیم که فرضیه                         A         (                    S                        m                             )                 {\displaystyle A(S_{m})}     سازگار است بنابراین                                                                R               &#x005E;                                          (         A         (                    S                        m                             )         )         =         0                 {\displaystyle {\hat {R}}(A(S_{m}))=0}    
                        Pr         [         R         (         A         (                    S                        m                             )         )         &gt;         &#x03F5;         ]         =         Pr         [         &#x2203;         h         &#x2208;                                 H                                        |                                                         R               &#x005E;                                          (         h         )         =         0         &#x2227;         R         (         h         )         &gt;         &#x03F5;                 {\displaystyle \Pr[R(A(S_{m}))&gt;\epsilon ]=\Pr[\exists h\in {\mathcal {H}}|{\hat {R}}(h)=0\wedge R(h)&gt;\epsilon }    
                        =         Pr                                 [                                        &#x22C3;                        h             &#x2208;                                             H                                                                                                R               &#x005E;                                          (         h         )         =         0         &#x2227;         R         (         h         )         &gt;         &#x03F5;                                 ]                                     {\displaystyle =\Pr {\biggl [}\bigcup _{h\in {\mathcal {H}}}{\hat {R}}(h)=0\wedge R(h)&gt;\epsilon {\biggr ]}}    
                        Pr                                 [                                        &#x22C3;                        i                                        A                        i                                                     ]                             &#x2264;                    &#x2211;                        i                             Pr         (                    A                        i                             )         .                 {\displaystyle \Pr {\biggl [}\bigcup _{i}A_{i}{\biggr ]}\leq \sum _{i}\Pr(A_{i}).}    
                        Pr         [         R         (         A         (                    S                        m                             )         )         &gt;         &#x03F5;         ]         &#x2264;                    &#x2211;                        h             &#x2208;                                             H                                                         Pr         [                                                R               &#x005E;                                          (         h         )         =         0         &#x2227;         R         (         h         )         &gt;         &#x03F5;         ]         &#x2264;                    &#x2211;                        h             &#x2208;                                             H                                                         Pr         [                                                R               &#x005E;                                          (         h         )         =         0                    |                  R         (         h         )         &gt;         &#x03F5;         ]                 {\displaystyle \Pr[R(A(S_{m}))&gt;\epsilon ]\leq \sum _{h\in {\mathcal {H}}}\Pr[{\hat {R}}(h)=0\wedge R(h)&gt;\epsilon ]\leq \sum _{h\in {\mathcal {H}}}\Pr[{\hat {R}}(h)=0|R(h)&gt;\epsilon ]}    
                                   &#x2211;                        h             &#x2208;                                             H                                                         (         1         &#x2212;         &#x03F5;                    )                        m                             =                    |                                          H                                        |                  (         1         &#x2212;         &#x03F5;                    )                        m                             &#x2264;                    |                                          H                                        |                             e                        &#x2212;             m             &#x03F5;                             &lt;         &#x03B4;                 {\displaystyle \sum _{h\in {\mathcal {H}}}(1-\epsilon )^{m}=|{\mathcal {H}}|(1-\epsilon )^{m}\leq |{\mathcal {H}}|e^{-m\epsilon }&lt;\delta }    
                        &#x21D2;         m         &#x2265;                                 1             &#x03F5;                             [         ln         &#x2061;                    |                                          H                                        |                  +         ln         &#x2061;                                 1             &#x03B4;                             ]         &#x21D2;                    M                        A                             (         &#x03F5;         ,         &#x03B4;         ,         D         )         &#x2264;                                 1             &#x03F5;                             [         ln         &#x2061;                    |                                          H                                        |                  +         ln         &#x2061;                                 1             &#x03B4;                             ]                 {\displaystyle \Rightarrow m\geq {\frac {1}{\epsilon }}[\ln |{\mathcal {H}}|+\ln {\frac {1}{\delta }}]\Rightarrow M_{A}(\epsilon ,\delta ,D)\leq {\frac {1}{\epsilon }}[\ln |{\mathcal {H}}|+\ln {\frac {1}{\delta }}]}    
