یادگیری تقویتی چند عاملی (MARL) زیر مجموعه ای از یادگیری تقویتی است . و بر بررسی رفتار چندین عاملی که در یک محدوده مشترک وجود دارند، تمرکز دارد.  هر عامل با به خاطر پاداش هایش انگیزه میگیرد و اقدام هایی را برای پیش بردن منافع خود انجام می دهد. امکان دارد این منافع با منافع بقیه عوامل اختلاف داشته باشد که منجر به پویایی پیچیده گروه می شود .
یادگیری تقویتی چند عاملی ارتباط نزدیکی با نظریه بازی و به ویژه بازی های تکراری دارد. مطالعه آن، جستجوی یافتن الگوریتم‌های ایدئال را که پاداش‌ها را به حداکثر می‌رسانند، با مجموعه‌ای جامعه‌شناختی از مفاهیم ترکیب می‌کند. در حالی که تحقیق در یادگیری تقویتی تک عاملی به یافتن الگوریتمی می‌پردازد که بیشترین امتیاز را برای یک عامل کسب می‌کند، تحقیقات در یادگیری تقویت چند عاملی معیارهای اجتماعی مانند همکاری, متقابل, حقوق صاحبان سهام, نفوذ اجتماعی, زبان و تبعیض را ارزیابی و کمی می‌کند.
در تنظیمات با اطلاعات کامل مانند بازی های شطرنج و برو گروه دموکراتیک کاملاً قابل مشاهده است. در تنظیمات با اطلاعاتی که کامل نیست، به ویژه در برنامه های کاربردی دنیای واقعی مانند اتومبیل های خودران, هر عامل به مشاهده ای دسترسی خواهد داشت که فقط قسمتی از اطلاعات مربوط به وضعیت فعلی را دارد.
هنگامی که چندین عامل در یک محیط مشترک عمل می کنند، ممکن است علایق آنها همسو یا نادرست باشد. MARL اجازه می دهد تا تمام هم ترازی های مختلف و نحوه تأثیر آنها بر رفتار عامل ها را بررسی کنید:
هنگامی که دو عامل در حال بازی یک بازی با حاصل جمع صفر در رقابت محض با یکدیگر هستند. بسیاری از بازی های سنتی مانند شطرنج و برو سقوط تحت این دسته, به عنوان انجام انواع دو نفره از بازی های مدرن مانند استارکرافت. از آنجایی که هر نماینده فقط می تواند با هزینه نماینده دیگر برنده شود، بسیاری از پیچیدگی ها از بین می روند. هیچ چشم‌اندازی برای ارتباط یا دوراهی‌های اجتماعی وجود ندارد، زیرا هیچ یک از نمایندگان برای انجام اقداماتی که به نفع حریف خود هستند، تشویق نمی‌شوند.
یکی از پیچیدگی‌هایی که در محیط‌های رقابتی محض از بین نمی‌رود،اتوکورریکول است. برنامه‌های آموزشی خودکار است. همانطور که خط مشی عوامل با استفاده از خود بازی, ممکن است چندین لایه یادگیری رخ دهد.
MARL برای بررسی چگونگی ارتباط عوامل مجزا با علایق یکسان و همکاری با یکدیگر استفاده می شود. تنظیمات همکاری خالص بازی‌های تعاونی تفریحی مورد بررسی قرار می گیرد مانند بازی های تعاونی و بیش از حد پخته شده, و همچنین سناریوهای دنیای واقعی در رباتیک بررسی می‌شوند.
اکثر سناریوهای دنیای واقعی که شامل چندین عامل است، عناصری از همکاری و رقابت دارند. برای مثال وقتی چند اتومبیل های خودران در حال برنامه ریزی مسیرهای مربوط به خود هستند که هر یک از آنها علایق متفاوتی دارند اما منحصر به فرد نیستند: هر خودرو مدت زمان لازم برای رسیدن به مقصد را به حداقل می رساند، اما همه خودروها دارای علاقه مشترکی برای اجتناب از برخورد ترافیک هستند.
در حالی که تحقیقات تئوری بازی ممکن است بر تعادل نش و اینکه یک سیاست ایدئال برای یک عامل می‌تواند باشد تمرکز کند، تحقیقات MARL بر چگونگی یادگیری این سیاست‌های ایدئال با استفاده از فرآیند آزمون و خطا تمرکز دارد. الگوریتم‌های یادگیری تقویتی که برای آموزش عوامل استفاده می‌شوند، پاداش خود عامل را به حداکثر می‌رسانند. تضاد بین نیازهای عوامل و نیازهای گروه موضوع تحقیق فعال است.
معضلات اجتماعی مانند معضل زندانی، شکار مرغ و گوزن «بازی‌های ماتریسی» هستند. هر عامل تنها یک اقدام را از بین دو اقدام ممکن انجام می‌دهد و یک ماتریس ساده 2x2 برای توصیف پاداشی که هر عامل با توجه به اقداماتی که هر عامل انجام می‌دهد، استفاده می‌شود.
در انسان ها و دیگر موجودات زنده، معضلات اجتماعی پیچیده تر هستند. عوامل در طول زمان اقدامات متعددی را انجام می دهند و تمایز بین همکاری و نقص به اندازه بازی های ماتریس واضح نیست. مفهوم یک معضل اجتماعی متوالی در سال 2017  به عنوان تلاشی برای مدل سازی این پیچیدگی معرفی شد. تحقیقات مداومی برای تعریف انواع SSD ها و نشان دادن رفتار مشارکتی در عواملی که در آنها عمل می کنند وجود دارد.
برنامه خودکار (جمع: برنامه های خودکار) یک مفهوم یادگیری تقویتی است که  در آزمایش‌های چند عاملی برجسته است. همانطور که عوامل عملکرد خود را بهبود می بخشند، محیط خود را تغییر می دهند. این تغییر در محیط بر خود و سایر عوامل تأثیر می گذارد. حلقه بازخورد منجر به چندین مرحله مجزا از یادگیری می شود که هر کدام به مرحله قبلی بستگی دارد. لایه های انباشته یادگیری، خود درسی نامیده می شود. برنامه‌های آموزشی خودکار به‌ویژه در محیط‌های متخاصم،  که در آن هر گروه از عوامل برای مقابله با استراتژی فعلی گروه مقابل رقابت می‌کنند، آشکار است.
بازی Hide and Seek یک نمونه قابل دسترس از یک برنامه خودکار است که در یک محیط خصمانه اتفاق می افتد. در این تجربه، گروهی از جویندگان در حال رقابت با گروهی از مخفی کنندگان هستند.زمانی که یکی از گروه ها نقشه جدیدی را یاد می گیرد، گروه مقابل نقشه خود را برای ارائه بهترین ضد ممکن تطبیق می دهد. زمانی که مخفی کنندگان یاد می‌گیرند که از جعبه‌ها برای درست کردن پناهگاه استفاده کنند، جویندگان با یادگیری استفاده از سطح شیب دار برای نفوذ به آن پناهگاه پاسخ می‌دهند. مخفی کننده‌ها با قفل کردن رمپ‌ها پاسخ می‌دهند و آن‌ها را برای استفاده جویندگان از دسترس خارج می‌کنند. سپس جویندگان با «گشت‌سواری در جعبه» پاسخ می‌دهند و از یک نقص در بازی برای نفوذ به پناهگاه سوء استفاده می‌کنند. هر «سطح» یادگیری یک اتفاق جدید است که سرآغاز آن مرحله قبلی است. این منجر به مجموعه ای از رفتارها می شود که هر کدام به سلف خود وابسته هستند.
برنامه های خودکار در تجربیات یادگیری تقویتی با مراحل مقایسه می شوند تکامل زندگی روی زمین و توسعه فرهنگ انسانی. یک مرحله مهم در تکامل 2-3 میلیارد سال پیش اتفاق افتاد اشکال زندگی فتوسنتز کننده شروع به تولید مقادیر عظیم از اکسیژن, تغییر تعادل گازها در جو. در مراحل بعدی تکامل, اشکال زندگی اکسیژن تنفس تکامل یافته, در نهایت منجر به زمین پستانداران و انسان است. این مراحل بعد تنها پس از مرحله فتوسنتز اکسیژن به طور گسترده ای در دسترس ساخته شده اتفاق می افتد. به طور مشابه, فرهنگ انسانی نمی تواند از طریق رفته انقلاب صنعتی در قرن 18 بدون منابع و بینش های کسب شده توسط انقلاب کشاورزی در حدود 10000 سال قبل از میلاد.
بعضی از مشکل های ذاتی در مورد یادگیری تقویت عمیق چند عاملی وجود دارد. محیط زیست است ساکن نیست, بنابراین املاک مارکوف نقض می شود: انتقال و پاداش تنها به وضعیت فعلی یک عامل بستگی ندارد.
